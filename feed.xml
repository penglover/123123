<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>IT&#39;s IT Blog</title>
  <subtitle>Penglover&#39;s Software house</subtitle>
  <link href="/feed.xml" rel="self"/>
  
  <link href="https://penglover.github.io/"/>
  <updated>2017-01-18T04:23:00.000Z</updated>
  <id>https://penglover.github.io/</id>
  
  <author>
    <name>Myeongsoo Kim</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>CSS3 tutorial1</title>
    <link href="https://penglover.github.io/2017/01/18/CSS3-tutorial1/"/>
    <id>https://penglover.github.io/2017/01/18/CSS3-tutorial1/</id>
    <published>2017-01-18T04:06:17.000Z</published>
    <updated>2017-01-18T04:23:00.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="css란-무엇"><a href="#css란-무엇" class="headerlink" title="css란 무엇?"></a>css란 무엇?</h1><p>css는 html의 형제라고 볼 수 있습니다.<br>html이 문서의 구조를 설계해주면 css가 그것을 꾸며주는 것이지요.<br>우리가 실제로 보는 문서는 css가 없다면 그냥 줄글형태일 것입니다.<br>우리가 편하게 웹을 사용할 수 있는 것은 어쩌면 css의 덕이 가장 크지요!<br>공부하기 위해서는 html의 지식이 선행되어야 합니다.<br>(제 이전 포스팅이 HTML5 포스팅이었습니다 ㅎㅎ 참고하세용)</p>
<h1 id="CSS3이란-무엇"><a href="#CSS3이란-무엇" class="headerlink" title="CSS3이란 무엇?"></a>CSS3이란 무엇?</h1><p>기존의 css는 아무래도 자바스크립트나 기타 플러그인에 많이 의지할 수 밖에 없었습니다.<br>우리는 동적인 웹사이트를 원하지만 css로만 코딩을 한다면 웹사이트는 너무 정적이기 때문이지요.<br>이러한 한계를 깨고있는 가장 최신버전의 css가 바로 CSS3입니다.<br>이미지가 왔다갔다 한다던가 자동으로 크기조절이 된다던가 하는 것들이 가능하게 됩니다.<br>심지어는 3차원적으로도 활용이 가능해서 매우 동적으로 변한것이 포인트입니다.<br>하지만 HTML5와 마찬가지로 구형브라우저에 대한 지원이 미미합니다.<br>그래서 자신의 타겟들의 연령대가 높거나 공공기관을 대상으로 한다면 CSS3의 최신기술들은 미뤄두는 것이 좋을수도 있습니다.<br>하지만 트렌디한 웹을 만들고 싶다면 도전해보세요!</p>
<h1 id="추천-공부방식은"><a href="#추천-공부방식은" class="headerlink" title="추천 공부방식은?"></a>추천 공부방식은?</h1><p>opentutorials.org에서 css강의를 우선 듣는 것을 추천합니다.<br>그리고 w3schools.com에서 튜토리얼을 진행해보세요.<br>그 후 마지막으로 서점에 가서 가능한 최신의 css3서적을 한권정도 읽으시면 됩니다.<br>그 이후에는 개발을 하다가 모르는 것이 나온다면 w3schools의 레퍼런스를 뒤지면서 하신다면 무리없이 개발이 가능할겁니다!</p>
]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;css란-무엇&quot;&gt;&lt;a href=&quot;#css란-무엇&quot; class=&quot;headerlink&quot; title=&quot;css란 무엇?&quot;&gt;&lt;/a&gt;css란 무엇?&lt;/h1&gt;&lt;p&gt;css는 html의 형제라고 볼 수 있습니다.&lt;br&gt;html이 문서의 구조를 설계해주면
    
    </summary>
    
      <category term="WEB" scheme="https://penglover.github.io/categories/WEB/"/>
    
      <category term="HTML/CSS" scheme="https://penglover.github.io/categories/WEB/HTML-CSS/"/>
    
    
      <category term="web" scheme="https://penglover.github.io/tags/web/"/>
    
      <category term="css" scheme="https://penglover.github.io/tags/css/"/>
    
  </entry>
  
  <entry>
    <title>HTML5를 효율적으로 빠르게 공부하는법</title>
    <link href="https://penglover.github.io/2017/01/18/HTML5-tutorial1/"/>
    <id>https://penglover.github.io/2017/01/18/HTML5-tutorial1/</id>
    <published>2017-01-18T03:30:44.000Z</published>
    <updated>2017-01-18T04:04:27.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="HTML이란-무엇"><a href="#HTML이란-무엇" class="headerlink" title="HTML이란 무엇?"></a>HTML이란 무엇?</h1><p>우선 html이야기를 하기 이전에 웹 이야기를 빼놓을 수가 없군요.<br>우리는 웹을 항상 접하며 삽니다.<br>네이버 다음 이런것들이 웹사이트들이닌깐요.<br>그렇다면 이 웹은 어떻게 구성되어 있을까요?<br>먼저 frontend - backend로 나뉘는데요.<br>프론트엔드는 사용자경험을 위한 UI제공을 하고 백엔드는 서버나 디비를 다룹니다.<br>한마디로 프론트엔드는 사용자에게 보이는 부분을 다루고요!<br>백엔드는 보이지 않는 부분을 다루는 것이지요.<br>HTML은 이 프론트엔드에서 가장 중요한 웹사이트의 구조를 담고있습니다.<br>구조를 잘 쌓아야 튼튼한 프론트엔드영역이 완성되겠지요?</p>
<h1 id="HTML5란-무엇"><a href="#HTML5란-무엇" class="headerlink" title="HTML5란 무엇?"></a>HTML5란 무엇?</h1><p>HTML5는 이런 html에서 가장 최신 버전의 문법입니다.<br>성능이 많이 발전해서 javascript와 힘을 합하면 멋진 게임도 만들어 낼 수 있습니다.<br>그리고 무엇보다 눈에 띄는 점은 역시 의미론적으로 변신했다는 것인데요!<br>HTML5가 의미론적으로 변하면서 구글검색엔진이나 네이버검색엔진 등이 효율적으로 우리의 웹문서를 읽게 되면서 많은 이득을 가져올 수 있게 되었습니다.<br>한마디로 웹을 우리의 입맛에 더 잘 맞게 개발할 수 있게 되었습니다!</p>
<h1 id="어떻게-공부해야-빠르고-튼튼할까"><a href="#어떻게-공부해야-빠르고-튼튼할까" class="headerlink" title="어떻게 공부해야 빠르고 튼튼할까?"></a>어떻게 공부해야 빠르고 튼튼할까?</h1><p>우선 제가 가장 추천하는 방법은 생활코딩 강의를 듣는 것입니다.<br>opentutorials.org 이곳에서 HTML강좌를 무료로 진행합니다.<br>그리고는 w3schools.com 에서 튜토리얼을 한번 진행합니다.<br>그리고는 다음으로 css공부를 진행하는 것을 추천드립니다.<br>html로 구조를 짠 다음에는 css로 맛깔나게 꾸미는게 재밌거든요!<br>그럼 다음글로 css3의 추천 공부법을 알려드리도록 하겠습니다.</p>
]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;HTML이란-무엇&quot;&gt;&lt;a href=&quot;#HTML이란-무엇&quot; class=&quot;headerlink&quot; title=&quot;HTML이란 무엇?&quot;&gt;&lt;/a&gt;HTML이란 무엇?&lt;/h1&gt;&lt;p&gt;우선 html이야기를 하기 이전에 웹 이야기를 빼놓을 수가 없군요.&lt;br
    
    </summary>
    
      <category term="WEB" scheme="https://penglover.github.io/categories/WEB/"/>
    
      <category term="HTML/CSS" scheme="https://penglover.github.io/categories/WEB/HTML-CSS/"/>
    
    
      <category term="web" scheme="https://penglover.github.io/tags/web/"/>
    
      <category term="html" scheme="https://penglover.github.io/tags/html/"/>
    
  </entry>
  
  <entry>
    <title>하이브리드 웹앱은 왜 생겼을까?</title>
    <link href="https://penglover.github.io/2017/01/17/why-hybrid-app/"/>
    <id>https://penglover.github.io/2017/01/17/why-hybrid-app/</id>
    <published>2017-01-17T07:36:41.000Z</published>
    <updated>2017-01-17T08:02:19.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="하이브리드-웹앱의-탄생"><a href="#하이브리드-웹앱의-탄생" class="headerlink" title="하이브리드 웹앱의 탄생"></a>하이브리드 웹앱의 탄생</h1><p>하이브리드 웹앱을 이야기하려면 웹앱과 네이티브앱에 대한 이야기가 필요합니다.<br>웹앱은 브라우저를 바탕으로 어디에서나 활용할 수 있습니다.<br>(대부분의 플랫폼에 브라우저는 있으닌깐요! 맥북이든 윈도우든 스마트폰이든 기타등등이든..)<br>네이티브 앱은 그와 반대로 개발환경과 대상이 제한적이지만 스마트폰의 하드웨어 기능을 직접 사용할 수 있는 특혜가 있습니다.<br>기타 여러가지 차이점이 있는데 아래표로 말을 대신하겠습니다.<br><img src="https://penglover.github.io/images/webappvsnative.jpeg" alt="네이티브앱vs웹앱"></p>
<p>그렇다면 둘의 장점을 취합할수는 없을까요?<br>당연히 이런 시도가 있었고 그 끝에 나온것이 하이브리드 웹앱입니다.<br>하이브리드앱이란 웹표준 기술을 그대로 사용하여 웹앱을 개발한 후에 오픈 소스 크로스 프레임워크를 이용하여 네이티브앱으로 변환시켜 배포되는 앱 형식을 의미합니다.<br>(대표적인 크로스 프레임워크로 폰갭이 있습니다.)<br>그리고 또한 네이티브방식과 웹앱의 방식을 섞어서 개발할 수도 있게 되었습니다.<br>하이브리드웹앱이 네이티브앱과 웹앱의 경계를 허물어 준것이지요!</p>
]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;하이브리드-웹앱의-탄생&quot;&gt;&lt;a href=&quot;#하이브리드-웹앱의-탄생&quot; class=&quot;headerlink&quot; title=&quot;하이브리드 웹앱의 탄생&quot;&gt;&lt;/a&gt;하이브리드 웹앱의 탄생&lt;/h1&gt;&lt;p&gt;하이브리드 웹앱을 이야기하려면 웹앱과 네이티브앱에 대한
    
    </summary>
    
      <category term="WEB" scheme="https://penglover.github.io/categories/WEB/"/>
    
      <category term="HybridWebApp" scheme="https://penglover.github.io/categories/WEB/HybridWebApp/"/>
    
    
      <category term="web" scheme="https://penglover.github.io/tags/web/"/>
    
      <category term="app" scheme="https://penglover.github.io/tags/app/"/>
    
  </entry>
  
  <entry>
    <title>하이브리드웹앱 vs 네이티브앱 비교해보자</title>
    <link href="https://penglover.github.io/2017/01/17/hybid-vs-native-app/"/>
    <id>https://penglover.github.io/2017/01/17/hybid-vs-native-app/</id>
    <published>2017-01-17T06:51:59.000Z</published>
    <updated>2017-01-17T08:02:07.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="누가-더-빠를까"><a href="#누가-더-빠를까" class="headerlink" title="누가 더 빠를까?"></a>누가 더 빠를까?</h1><p>흔히들 네이티브앱의 가장 큰 강점으로 빠르기를 꼽습니다.<br>그런데 정말 빠를까요? 또 빠르면 얼만큼 빠를까요?<br>정확히 말씀드릴 수 있는부분은 결코 성능차이가 크지 않다는 것입니다.<br>물론 매우 무겁고 힘든 프로젝트들은 당연히 네이티브로 가야하는 것이 맞습니다.<br>그러나 평범한 프로젝트들은 하이브리드앱과 네이티브앱이 별 속도차이가 없습니다.<br>(개인적인 견해이긴 하지만 실제로 두 방법으로 모두 개발하는 개발사에서 이야기를 들었습니다.)<br>자바스크립트로 앱을 만들어주는 프레임워크인 fuse도 이미 네이티브를 따라잡았다고 광고를 하죠.<br>하이브리드 웹앱이 일반적으로 훨씬 개발속도가 빠른 만큼 자신의 프로젝트의 규모를 보고 잘 판단해서 결정해야 할 것 같습니다.<br>속도는 한마디로 ‘부분적으로 네이티브가 더 빠르다’라고 할 수 있겠습니다.</p>
<h1 id="핸드폰-자원을-얼마나-활용가능할까-API"><a href="#핸드폰-자원을-얼마나-활용가능할까-API" class="headerlink" title="핸드폰 자원을 얼마나 활용가능할까?(API)"></a>핸드폰 자원을 얼마나 활용가능할까?(API)</h1><p>흔히들 하이브리드 웹앱은 네이티브가 할 수 있는 수많은 일들을 아예 못한다고 생각합니다.<br>하지만 큰 오산입니다. 푸쉬알림 등등 거의 전부다 가능합니다!<br>물론 일부 문서화가 잘 안되어있어서 힘든 것들이 있지요.<br>심각한 커스터마이징이 필요하다면 네이티브가 옳은 선택일 것입니다.<br>하지만 일반적인 UI를 가지고 푸쉬알림 등의 기능만 필요하다면 하이브리드 웹앱이 더 좋은 판단이라고 생각됩니다.</p>
<h1 id="유지보수는-어느쪽이-더-쉬울까"><a href="#유지보수는-어느쪽이-더-쉬울까" class="headerlink" title="유지보수는 어느쪽이 더 쉬울까?"></a>유지보수는 어느쪽이 더 쉬울까?</h1><p>하이브리드 웹앱이 압도적으로 더 쉽습니다.<br>단순히 안드로이드와 IOS를 동시에 관리할 수 있기 때문이 아닙니다.<br>서버에서 관리할 수 있는 자원이 태생적으로 더 많을 수 밖에 없습니다.<br>따라서 유지보수 또한 하이브리드 웹앱이 일반적으로 수월합니다.</p>
<h1 id="개발기간-단가는-어떨까"><a href="#개발기간-단가는-어떨까" class="headerlink" title="개발기간 + 단가는 어떨까?"></a>개발기간 + 단가는 어떨까?</h1><p>개발기간은 네이티브앱이 압도적으로 길게 걸립니다.<br>단가 또한 마찬가지이지요.<br>저는 네이티브앱 개발이 3배힘들다고 생각합니다.<br>IOS와 안드로이드를 둘다 만들어줘야 할 뿐아니라 개발자 단가도 웹개발자에 비해 앱개발자가 더 비싼편입니다.</p>
<h1 id="결론"><a href="#결론" class="headerlink" title="결론"></a>결론</h1><p>커스터마이징이 심한 어플 + 매우 무거운 어플이라면 네이티브 앱을,<br>그런게 아니라면 하이브리드 웹앱을 추천합니다.<br>또한 서버에서 관리할 자원이 많아도 하이브리드 웹앱을 추천합니다.</p>
]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;누가-더-빠를까&quot;&gt;&lt;a href=&quot;#누가-더-빠를까&quot; class=&quot;headerlink&quot; title=&quot;누가 더 빠를까?&quot;&gt;&lt;/a&gt;누가 더 빠를까?&lt;/h1&gt;&lt;p&gt;흔히들 네이티브앱의 가장 큰 강점으로 빠르기를 꼽습니다.&lt;br&gt;그런데 정말 빠를
    
    </summary>
    
      <category term="WEB" scheme="https://penglover.github.io/categories/WEB/"/>
    
      <category term="HybridWebApp" scheme="https://penglover.github.io/categories/WEB/HybridWebApp/"/>
    
    
      <category term="web" scheme="https://penglover.github.io/tags/web/"/>
    
      <category term="app" scheme="https://penglover.github.io/tags/app/"/>
    
  </entry>
  
  <entry>
    <title>sigmoid함수가 버려진 이유 - ReLU</title>
    <link href="https://penglover.github.io/2017/01/15/relu-vs-sigmoid/"/>
    <id>https://penglover.github.io/2017/01/15/relu-vs-sigmoid/</id>
    <published>2017-01-15T12:53:25.000Z</published>
    <updated>2017-01-15T13:03:36.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="ReLU"><a href="#ReLU" class="headerlink" title="ReLU"></a>ReLU</h1><p>많은 분들이 아시듯이 머신러닝에서는 sigmoid함수를 써서 작업했었습니다.<br>그 이유는 아래의 글에서 이미 다루었습니다.<br><a href="https://penglover.github.io/2017/01/15/algorithm-sigmoid/">https://penglover.github.io/2017/01/15/algorithm-sigmoid/</a></p>
<p>그런데 이 sigmoid는 사실 전에 머신러닝 붐을 약화시킨 주범입니다.<br>바로 hidden layer 즉 층이 깊어지면 깊어질수록 정확성을 오히려 떨어뜨린다는 것입니다.<br>sigmoid 특성상 마이너스 값을 0에 가깝게 만듭니다.<br>따라서 관계가 깊어지면 깊어질수록 미분의 체인룰에 의해 sigmoid된 값들이 곱해질때<br>모두다 0에 가까운 값에 수렴하게 되어 input 값이 최종값에 아무런 영향을 끼치지 못하는 사태가 벌어지게 됩니다.<br>이를 위해 탄생한게 ReLU입니다.<br>매우 심플한데요.<br>0이하의 값이 들어오면 0을 출력하고 0이상의 값이 오면 비례함수로 그냥 내보내는 겁니다.<br><img src="https://upload.wikimedia.org/wikipedia/en/thumb/6/6c/Rectifier_and_softplus_functions.svg/440px-Rectifier_and_softplus_functions.svg.png" alt="ReLU"><br>감이 오시죠?<br>아! 물론 sigmoid는 여전히 마지막 layer에서 사용하고 있습니다.<br>마지막에는 0에서 1사이의 값으로 출력할 필요가 있거든요!<br>실제로 이 방법으로 hidden layer를 늘렸을때 즉 딥러닝에서 엄청난 결과를 가져옵니다.<br>감이 안오시는 분들은 아래의 김성훈 교수님의 강의를 들어보세요 ㅎㅎ<br><div class="video-container"><iframe src="//www.youtube.com/embed/cKtg_fpw88c" frameborder="0" allowfullscreen></iframe></div></p>
]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;ReLU&quot;&gt;&lt;a href=&quot;#ReLU&quot; class=&quot;headerlink&quot; title=&quot;ReLU&quot;&gt;&lt;/a&gt;ReLU&lt;/h1&gt;&lt;p&gt;많은 분들이 아시듯이 머신러닝에서는 sigmoid함수를 써서 작업했었습니다.&lt;br&gt;그 이유는 아래의 글에서 이미
    
    </summary>
    
      <category term="ML" scheme="https://penglover.github.io/categories/ML/"/>
    
      <category term="DeepLearning" scheme="https://penglover.github.io/categories/ML/DeepLearning/"/>
    
    
      <category term="machinelearning" scheme="https://penglover.github.io/tags/machinelearning/"/>
    
  </entry>
  
  <entry>
    <title>백프로퍼게이션(역전파)에 대한 친절한 강의</title>
    <link href="https://penglover.github.io/2017/01/15/backpropagation/"/>
    <id>https://penglover.github.io/2017/01/15/backpropagation/</id>
    <published>2017-01-15T11:32:11.000Z</published>
    <updated>2017-01-15T11:41:27.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="backpropagation"><a href="#backpropagation" class="headerlink" title="backpropagation"></a>backpropagation</h1><p>역전파 알고리즘, 즉 백프로퍼게이션 알고리즘은 머신러닝, 딥러닝의 핵심으로 많이 쓰입니다.<br>어떻게 뉴런들을 학습시킬 것이냐? 에 대한 해답을 던져준 것이기 때문이죠.<br>쉽게 말하면 feed forward를 통해 결과값을 우선 얻습니다.<br>그리곤 실제값과의 차이를 통해 backpropagation으로 값들을 update시키죠.<br>각 값들을 update시키는 기준은 무엇일까요?<br>바로 미분을 통해서입니다.<br>미분을 아는분들은 감이 오실겁니다.<br>미분은 해당 값에서의 변화량이지요.<br>쉽게 말해 전체 알고리즘을 f라고 두고 해당점을 a라고 둔다면?<br>f를 a에 대해 미분하면 순간변화량, 즉 a가 f에 미치는 영향을 알 수 있습니다.<br>이에 따라서 값을 매기가 update 자료로 삼지요.<br>아래는 김성훈 교수님의 아주 친절한 강의입니다.<br><div class="video-container"><iframe src="//www.youtube.com/embed/573EZkzfnZ0" frameborder="0" allowfullscreen></iframe></div></p>
<p>미분을 잘 모르는 분들을 위해서도 강의를 찍으셨습니다.<br><div class="video-container"><iframe src="//www.youtube.com/embed/oZyvmtqLmLo" frameborder="0" allowfullscreen></iframe></div></p>
]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;backpropagation&quot;&gt;&lt;a href=&quot;#backpropagation&quot; class=&quot;headerlink&quot; title=&quot;backpropagation&quot;&gt;&lt;/a&gt;backpropagation&lt;/h1&gt;&lt;p&gt;역전파 알고리즘, 즉 백프로퍼게이
    
    </summary>
    
      <category term="ML" scheme="https://penglover.github.io/categories/ML/"/>
    
      <category term="algorithm" scheme="https://penglover.github.io/categories/ML/algorithm/"/>
    
    
      <category term="machinelearning" scheme="https://penglover.github.io/tags/machinelearning/"/>
    
      <category term="algorithm" scheme="https://penglover.github.io/tags/algorithm/"/>
    
  </entry>
  
  <entry>
    <title>딥러닝이란 무엇일까? 김성훈 교수님의 말씀!</title>
    <link href="https://penglover.github.io/2017/01/15/what-is-deep-learning/"/>
    <id>https://penglover.github.io/2017/01/15/what-is-deep-learning/</id>
    <published>2017-01-15T10:09:31.000Z</published>
    <updated>2017-01-15T10:30:03.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="딥러닝이란"><a href="#딥러닝이란" class="headerlink" title="딥러닝이란?"></a>딥러닝이란?</h1><p>딥러닝이란 용어가 최근들어 많이 쓰이고 있습니다.<br>머신 러닝의 일종으로 간단한 learning 구조를 쌓아 올려가며 순차적으로 학습하는 계층적 구조의 학습법이라는 정의가 있기는 하지만 잘 와닿지가 않죠?<br>김성훈 교수님의 강의를 공유합니다.</p>
<p><strong>딥러닝이란(상)</strong><br><div class="video-container"><iframe src="//www.youtube.com/embed/n7DNueHGkqE" frameborder="0" allowfullscreen></iframe></div><br><strong>딥러닝이란(하)</strong><br><div class="video-container"><iframe src="//www.youtube.com/embed/AByVbUX1PUI" frameborder="0" allowfullscreen></iframe></div></p>
<p><a href="http://hunkim.github.io/ml/" rel="external nofollow noopener noreferrer" target="_blank">http://hunkim.github.io/ml/</a> 에 가면 더 많은 강의들이 있습니다.</p>
]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;딥러닝이란&quot;&gt;&lt;a href=&quot;#딥러닝이란&quot; class=&quot;headerlink&quot; title=&quot;딥러닝이란?&quot;&gt;&lt;/a&gt;딥러닝이란?&lt;/h1&gt;&lt;p&gt;딥러닝이란 용어가 최근들어 많이 쓰이고 있습니다.&lt;br&gt;머신 러닝의 일종으로 간단한 learning 
    
    </summary>
    
      <category term="ML" scheme="https://penglover.github.io/categories/ML/"/>
    
      <category term="DeepLearning" scheme="https://penglover.github.io/categories/ML/DeepLearning/"/>
    
    
      <category term="machinelearning" scheme="https://penglover.github.io/tags/machinelearning/"/>
    
  </entry>
  
  <entry>
    <title>머신러닝 코드 최적화하기 by rate, overfitting, regularization</title>
    <link href="https://penglover.github.io/2017/01/15/how-can-upgrade-mlcode/"/>
    <id>https://penglover.github.io/2017/01/15/how-can-upgrade-mlcode/</id>
    <published>2017-01-15T08:07:38.000Z</published>
    <updated>2017-01-15T10:11:44.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="머신러닝-코드-최적화하기"><a href="#머신러닝-코드-최적화하기" class="headerlink" title="머신러닝 코드 최적화하기"></a>머신러닝 코드 최적화하기</h1><p><strong>rate</strong><br>항상 우리는 머신러닝 코드를 짤때 learning rate라는 값을 줍니다.<br>gradient descent알고리즘을 쓸 때에 업데이트 정도를 조절해주는데요.<br>우리는 이 learning rate 를 조절함으로써 코드를 최적화 할 수 있습니다.<br>너무 작은값을 주면 어떻게 될까요?<br>또는 너무 큰값을 주면 어떻게 될까요?<br><img src="https://penglover.github.io/images/learningrate.png" alt="compare_learningrate"><br>위의 그림처럼 되어서 최적화가 안됩니다.<br>해결방안은?<br>print로 꾸준히 cost함수의 변화를 체크하는 것이 최선입니다.</p>
<p><strong>overfitting</strong><br>overfitting이라 하면 주로 test data가 적어서 일어납니다.<br>무리하게 적은 데이터로 fitting을 하려다보니 이상해 지는 것이지요.<br>또는 weight간의 값이 편차가 심하거나 해도 마찬가지로 일어납니다.<br>그래프가 구부러져 보인다고 해서 ‘구부러졌다’라고 표현하기도 합니다.<br>표준정규분포를 혹시 아시나요?<br>z = (x-평균)/표준편차<br>고등학교 수학시간에 한번 보셨을 겁니다.<br>이것을 이용해서 weight간의 격차를 일반화해줌으로서 해결하는 경우가 대부분입니다.<br>또는 regularization을 통해 해결할 수 있는데요.</p>
<p><strong>regularization</strong><br>기존의 우리가 cost를 구하는 개념에서 weight의 제곱을 또 추가한것을 구하는 개념입니다.<br>gradient descent 알고리즘을 사용한다면 자동으로 weight의 제곱까지 고려해서 minimize를 시킬 것이고 그에따라서 자동으로 weight의 값들도 하향 평준화 시켜서 값을 낮춤으로써 구부러짐을 방지해주지요.<br>구부러짐이 뭐지 하는생각이 들 수 있습니다.<br><img src="https://penglover.github.io/images/regularization.png" alt="regularization"><br><img src="http://cs231n.github.io/assets/nn1/reg_strengths.jpeg" alt="overfitting_example"></p>
<p>위에서 보이듯 람다값이 작을수록 weight 값을 신경쓰지 않겠다는 것입니다.</p>
]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;머신러닝-코드-최적화하기&quot;&gt;&lt;a href=&quot;#머신러닝-코드-최적화하기&quot; class=&quot;headerlink&quot; title=&quot;머신러닝 코드 최적화하기&quot;&gt;&lt;/a&gt;머신러닝 코드 최적화하기&lt;/h1&gt;&lt;p&gt;&lt;strong&gt;rate&lt;/strong&gt;&lt;br&gt;항
    
    </summary>
    
      <category term="ML" scheme="https://penglover.github.io/categories/ML/"/>
    
      <category term="algorithm" scheme="https://penglover.github.io/categories/ML/algorithm/"/>
    
    
      <category term="machinelearning" scheme="https://penglover.github.io/tags/machinelearning/"/>
    
      <category term="algorithm" scheme="https://penglover.github.io/tags/algorithm/"/>
    
  </entry>
  
  <entry>
    <title>텐서플로우에서 softmax 메서드를 사용해 봅시다!</title>
    <link href="https://penglover.github.io/2017/01/15/tensorflow-softmaxC/"/>
    <id>https://penglover.github.io/2017/01/15/tensorflow-softmaxC/</id>
    <published>2017-01-15T06:07:59.000Z</published>
    <updated>2017-01-15T07:17:07.000Z</updated>
    
    <content type="html"><![CDATA[<p>우선 softmax란?<br>logistic을 지난번 포스팅에서 다뤘죠?<br>(<a href="https://penglover.github.io/2017/01/15/tensorflow-logisticC/">https://penglover.github.io/2017/01/15/tensorflow-logisticC/</a>)<br>그것을 일반화 한것이라고 보면 됩니다.<br>logistic은 계산을 해서 1, 0만 나누었다면<br>softmax는 같은 계산을 해서 각 class별로 확률을 매기죠.<br>가장 높은 확률의 편을 들어주는 것입니다.</p>
<p>텐서플로우가 아니라면 softmax 부분을 어떻게 구현해야 할까요?<br>일일히 class별로 weight와 bias를 계산해서 sigmoid 씌우고 주저리주저리…<br>어휴 참 끔찍합니다.<br>다행히 tensorflow에서는 메서드로 이를 제공하는데요.<br>아래의 코드는 weight와 bias를 행렬로 처리해서 W로 묶어서 두었습니다.<br>hypothesis, 즉 기대값은 X와 W의 행렬곱을 softmax처리 한 것입니다.<br>cost함수는 오류를 극대화 하기 위해서 + 선형성을 위해서 저렇게 한 것이라고 생각하면 됩니다.</p>
<p>softmax에 대해서 아는 분이라면 다음의 코드가 쉽게 이해가 가실겁니다.<br><figure class="highlight plain"><figcaption><span>input.txt</span></figcaption><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line">#x0 x1 x2 y[A   B   C]</div><div class="line">1   2   1   0   0   1</div><div class="line">1   3   2   0   0   1</div><div class="line">1   3   4   0   0   1</div><div class="line">1   5   5   0   1   0</div><div class="line">1   7   5   0   1   0</div><div class="line">1   2   5   0   1   0</div><div class="line">1   6   6   1   0   0</div><div class="line">1   7   7   1   0   0</div></pre></td></tr></table></figure><br>아래는 예제 코드입니다.<br><figure class="highlight plain"><figcaption><span>softmax.py</span></figcaption><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div></pre></td><td class="code"><pre><div class="line">import tensorflow as tf</div><div class="line">import numpy as np</div><div class="line"></div><div class="line">xy = np.loadtxt(&apos;input.txt&apos;, unpack=True, dtype=&apos;float32&apos;)</div><div class="line"></div><div class="line">x_data = np.transpose(xy[0:3])</div><div class="line">y_data = np.transpose(xy[3:])</div><div class="line"></div><div class="line">X = tf.placeholder(&quot;float&quot;, [None, 3])</div><div class="line">Y = tf.placeholder(&quot;float&quot;, [None, 3])</div><div class="line"></div><div class="line">W = tf.Variable(tf.zeros([3, 3]))</div><div class="line"></div><div class="line">hypothesis = tf.nn.softmax(tf.matmul(X, W))</div><div class="line"></div><div class="line">learning_rate = 0.01</div><div class="line"></div><div class="line">cost = tf.reduce_mean(-tf.reduce_sum(Y * tf.log(hypothesis), reduction_indices=1))</div><div class="line"></div><div class="line">optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(cost)</div><div class="line"></div><div class="line"></div><div class="line">init = tf.global_variables_initializer()</div><div class="line"></div><div class="line">sess = tf.Session()</div><div class="line"></div><div class="line">sess.run(init)</div><div class="line"></div><div class="line">for step in range(2001):</div><div class="line">    sess.run(optimizer, feed_dict=&#123;X: x_data, Y: y_data&#125;)</div><div class="line">    if step % 200 == 0:</div><div class="line">         print (step, sess.run(cost, feed_dict=&#123;X: x_data, Y: y_data&#125;), sess.run(W))</div><div class="line"></div><div class="line">a = sess.run(hypothesis, feed_dict=&#123;X: [[1, 11, 7]]&#125;)</div><div class="line">print (&quot;a :&quot;, a, sess.run(tf.arg_max(a, 1)))</div><div class="line"></div><div class="line">b = sess.run(hypothesis, feed_dict=&#123;X: [[1, 3, 4]]&#125;)</div><div class="line">print (&quot;b :&quot;, b, sess.run(tf.arg_max(b, 1)))</div><div class="line"></div><div class="line">c = sess.run(hypothesis, feed_dict=&#123;X: [[1, 1, 0]]&#125;)</div><div class="line">print (&quot;c :&quot;, c, sess.run(tf.arg_max(c, 1)))</div></pre></td></tr></table></figure><br><strong>결과값</strong><br>0 1.09048 [[-0.00083333  0.00041667  0.00041667]<br> [ 0.00166667  0.00291667 -0.00458333]<br> [ 0.00166667  0.00416667 -0.00583333]]<br>200 0.985653 [[-0.21679303 -0.05050437  0.26729742]<br> [ 0.02901031 -0.06265054  0.03364029]<br> [ 0.04244109  0.12451769 -0.16695869]]<br>400 0.926073 [[-0.41495511 -0.10318027  0.51813519]<br> [ 0.03762176 -0.10302337  0.06540174]<br> [ 0.07457665  0.17761268 -0.25218898]]<br>600 0.879342 [[-0.59596533 -0.1515553   0.74752003]<br> [ 0.04480708 -0.11983915  0.07503238]<br> [ 0.10447746  0.20644082 -0.31091776]]<br>800 0.840971 [[-0.76270223 -0.19499816  0.95770001]<br> [ 0.05223157 -0.12450957  0.07227841]<br> [ 0.13095778  0.22218271 -0.35314   ]]<br>1000 0.808647 [[-0.91752577 -0.2334879   1.15101326]<br> [ 0.06007884 -0.12292791  0.06284945]<br> [ 0.15438823  0.23068959 -0.38507724]]<br>1200 0.780959 [[-1.06231129 -0.26727253  1.32958329]<br> [ 0.06808005 -0.11823834  0.05015875]<br> [ 0.17550454  0.23514733 -0.41065112]]<br>1400 0.756943 [[-1.19854808 -0.29670808  1.49525583]<br> [ 0.07591439 -0.11214777  0.03623381]<br> [ 0.19498996  0.237331   -0.43232018]]<br>1600 0.735892 [[-1.32743537 -0.32218221  1.64961684]<br> [ 0.08333746 -0.10557999  0.022243  ]<br> [ 0.21336642  0.23823628 -0.45160189]]<br>1800 0.717269 [[-1.44994974 -0.34407791  1.79402602]<br> [ 0.09020081 -0.09902246  0.00882213]<br> [ 0.23099625  0.23841871 -0.46941414]]<br>2000 0.700649 [[-1.56689739 -0.36275655  1.92965221]<br> [ 0.09643649 -0.09271803 -0.00371792]<br> [ 0.24811605  0.23818412 -0.48629922]]<br>a : [[ 0.68849677  0.26731515  0.04418808]] [0]<br>b : [[ 0.24322268  0.44183081  0.3149465 ]] [1]<br>c : [[ 0.02974809  0.08208466  0.8881672 ]] [2]</p>
<p>정말 놀랍죠?<br>참고로 transpose는 열과 행을 바꾸는 것입니다.<br>reduction_indices=1 이부분도 뭔지 모르실수가 있는데 아래의 링크에 설명했습니다.<br><a href="https://penglover.github.io/2017/01/15/tensorflow-reduction-indices/">https://penglover.github.io/2017/01/15/tensorflow-reduction-indices/</a></p>
<p>softmax가 이해가 안가시는분들은 이걸봐주세요.<br>김성훈님의 강의입니다.<br><div class="video-container"><iframe src="//www.youtube.com/embed/MFAnsx1y9ZI" frameborder="0" allowfullscreen></iframe></div><br>cost가 이해가 안가시는 분들은 이걸봐주세요.<br>마찬가지로 김성훈 교수님의 강의입니다.<br><div class="video-container"><iframe src="//www.youtube.com/embed/jMU9G5WEtBc" frameborder="0" allowfullscreen></iframe></div></p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;우선 softmax란?&lt;br&gt;logistic을 지난번 포스팅에서 다뤘죠?&lt;br&gt;(&lt;a href=&quot;https://penglover.github.io/2017/01/15/tensorflow-logisticC/&quot;&gt;https://penglover.git
    
    </summary>
    
      <category term="ML" scheme="https://penglover.github.io/categories/ML/"/>
    
      <category term="TensorFlow" scheme="https://penglover.github.io/categories/ML/TensorFlow/"/>
    
    
      <category term="machinelearning" scheme="https://penglover.github.io/tags/machinelearning/"/>
    
      <category term="tensorflow" scheme="https://penglover.github.io/tags/tensorflow/"/>
    
  </entry>
  
  <entry>
    <title>텐서플로우에서 reduction_indices 속성은 무엇일까?</title>
    <link href="https://penglover.github.io/2017/01/15/tensorflow-reduction-indices/"/>
    <id>https://penglover.github.io/2017/01/15/tensorflow-reduction-indices/</id>
    <published>2017-01-15T05:29:16.000Z</published>
    <updated>2017-01-15T05:33:48.000Z</updated>
    
    <content type="html"><![CDATA[<p>텐서플로우를 공부하다보면 reduction_indices 속성이 등장합니다.<br>reduce_mean이라든가 연산메서드에서 등장하는 속성인데요.<br><figure class="highlight plain"><figcaption><span>simple.txt</span></figcaption><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">&apos;x&apos; is [[1., 1.]</div><div class="line">        [2., 2.]]</div></pre></td></tr></table></figure><br>다음의 행렬이 있다고 해보겠습니다.<br>결과값은 어떻게 될까요?<br>tf.reduce_mean(x) ==&gt; 1.5<br>tf.reduce_mean(x, 0) ==&gt; [1.5, 1.5]<br>tf.reduce_mean(x, 1) ==&gt; [1.,  2.]</p>
<p>자 아시겠죠?<br>아무 값도 주지 않으면 전부다 처리해버립니다.<br>0으로 하면 열끼리 처리하고 1로 하면 행끼리 처리합니다.<br>도움이 되셨길 바라며 포스팅 마무리하겠습니다~</p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;텐서플로우를 공부하다보면 reduction_indices 속성이 등장합니다.&lt;br&gt;reduce_mean이라든가 연산메서드에서 등장하는 속성인데요.&lt;br&gt;&lt;figure class=&quot;highlight plain&quot;&gt;&lt;figcaption&gt;&lt;span&gt;si
    
    </summary>
    
      <category term="ML" scheme="https://penglover.github.io/categories/ML/"/>
    
      <category term="TensorFlow" scheme="https://penglover.github.io/categories/ML/TensorFlow/"/>
    
    
      <category term="machinelearning" scheme="https://penglover.github.io/tags/machinelearning/"/>
    
      <category term="tensorflow" scheme="https://penglover.github.io/tags/tensorflow/"/>
    
  </entry>
  
  <entry>
    <title>텐서플로우로 logistic classification 구현해보자</title>
    <link href="https://penglover.github.io/2017/01/15/tensorflow-logisticC/"/>
    <id>https://penglover.github.io/2017/01/15/tensorflow-logisticC/</id>
    <published>2017-01-15T04:19:22.000Z</published>
    <updated>2017-01-15T05:30:03.000Z</updated>
    
    <content type="html"><![CDATA[<p>logistic classification은 다들알고 계시죠?<br>true인지 false인지를 판가름해봅시다.<br>실제로 양자택일의 상황이 올 경우가 굉장히 많지요.<br>자, 코드부터 보겠습니다.<br>input.txt는 다음과 같습니다.<br><figure class="highlight plain"><figcaption><span>input.txt</span></figcaption><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line">#x0 x1 x2 y</div><div class="line">1   2   1   0</div><div class="line">1   3   2   0</div><div class="line">1   3   5   0</div><div class="line">1   5   5   1</div><div class="line">1   7   5   1</div><div class="line">1   2   5   1</div></pre></td></tr></table></figure><br>코드부분 입니다.<br><figure class="highlight plain"><figcaption><span>logisticC.py</span></figcaption><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div></pre></td><td class="code"><pre><div class="line">import tensorflow as tf</div><div class="line">import numpy as np</div><div class="line"></div><div class="line">xy = np.loadtxt(&apos;input.txt&apos;, unpack=True, dtype=&apos;float32&apos;)</div><div class="line">x_data = xy[0:-1]</div><div class="line">y_data = xy[-1]</div><div class="line"></div><div class="line">X = tf.placeholder(tf.float32)</div><div class="line">Y = tf.placeholder(tf.float32)</div><div class="line"></div><div class="line">W = tf.Variable(tf.random_uniform([1, len(x_data)], -1.0, 1.0))</div><div class="line"></div><div class="line">h = tf.matmul(W, X)</div><div class="line">hypothesis = tf.div(1., 1. + tf.exp(-h))</div><div class="line"></div><div class="line">cost = -tf.reduce_mean(Y * tf.log(hypothesis) + (1 - Y) * tf.log(1 - hypothesis))</div><div class="line"></div><div class="line">a = tf.Variable(0.1)  # learning rate, alpha</div><div class="line">optimizer = tf.train.GradientDescentOptimizer(a)</div><div class="line">train = optimizer.minimize(cost)  # goal is minimize cost</div><div class="line"></div><div class="line">init = tf.global_variables_initializer()</div><div class="line"></div><div class="line">sess = tf.Session()</div><div class="line">sess.run(init)</div><div class="line"></div><div class="line">for step in range(2001):</div><div class="line">    sess.run(train, feed_dict=&#123;X: x_data, Y: y_data&#125;)</div><div class="line">    if step % 200 == 0:</div><div class="line">        print (step, sess.run(cost, feed_dict=&#123;X: x_data, Y: y_data&#125;), sess.run(W))</div><div class="line"></div><div class="line">print (&apos;-----------------------------------------&apos;)</div><div class="line">print (sess.run(hypothesis, feed_dict=&#123;X: [[1], [2], [2]]&#125;) &gt; 0.5)</div><div class="line">print (sess.run(hypothesis, feed_dict=&#123;X: [[1], [5], [5]]&#125;) &gt; 0.5)</div><div class="line">print (sess.run(hypothesis, feed_dict=&#123;X: [[1, 1], [4, 0], [2, 10]]&#125;) &gt; 0.5)</div></pre></td></tr></table></figure></p>
<p><strong>결과값</strong><br>0 0.919001 [[ 0.8754766  -0.10433824  0.33632374]]<br>200 0.509501 [[-1.38300133  0.11766662  0.33868256]]<br>400 0.42692 [[-2.6384747   0.24237575  0.51069313]]<br>600 0.391719 [[-3.46154785  0.31578434  0.6304763 ]]<br>800 0.373097 [[-4.06127024  0.36348528  0.72200185]]<br>1000 0.361825 [[-4.52822399  0.39683989  0.79584837]]<br>1200 0.354366 [[-4.90821457  0.42141104  0.85761738]]<br>1400 0.34911 [[-5.22723818  0.44022152  0.91062367]]<br>1600 0.345229 [[-5.5013628   0.45505521  0.95699048]]<br>1800 0.342259 [[-5.74115181  0.46703169  0.99815571]]</p>
<h2 id="2000-0-339921-5-95390177-0-47688928-1-03513932"><a href="#2000-0-339921-5-95390177-0-47688928-1-03513932" class="headerlink" title="2000 0.339921 [[-5.95390177  0.47688928  1.03513932]]"></a>2000 0.339921 [[-5.95390177  0.47688928  1.03513932]]</h2><p>[[False]]<br>[[ True]]<br>[[False  True]]</p>
<p>주목해야할 부분은 cost함수 입니다.<br>왜 시그모이드 함수를 씌우고 log를 취했을까요?<br>0, 1의 값만을 갖는 true or false의 문제이기 때문인데요.<br>기존의 LinearRegression을 그대로 적용하면 최적화에 어려움이 있습니다.<br>어떤 어려움인지는 맨 아래 링크에 나와있구요.<br>그래서 sigmoid를 씌운 것입니다.</p>
<p>log를 취한 이유는 gradient descent 알고리즘의 최적화와 연관이 있는데요.<br>그냥 sigmoid 만 취하면 함수가 울퉁불퉁해져서 최적화가 힘듭니다.<br>때문에 log를 취해서 적용시키려고 하는 것이지요.<br>cost에 대해 모르시겠는 분들은 다음 동영상으로 학습해주세요.<br>김성훈 교수님의 강의입니다.<br><div class="video-container"><iframe src="//www.youtube.com/embed/6vzchGYEJBc" frameborder="0" allowfullscreen></iframe></div></p>
<p>기존의 LinearRegression 함수에 시그모이드 함수를 취했다는 것 이외에는 별 다른게 없죠?<br>하지만 sigmoid 함수의 필요성과 cost함수의 변화를 이해했다면 큰 발전입니다.<br>시그모이드 함수를 왜 취했는가를 모르신다면 아래의 url로 이동해주세요.<br><a href="https://penglover.github.io/2017/01/15/algorithm-sigmoid/">https://penglover.github.io/2017/01/15/algorithm-sigmoid/</a></p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;logistic classification은 다들알고 계시죠?&lt;br&gt;true인지 false인지를 판가름해봅시다.&lt;br&gt;실제로 양자택일의 상황이 올 경우가 굉장히 많지요.&lt;br&gt;자, 코드부터 보겠습니다.&lt;br&gt;input.txt는 다음과 같습니다.&lt;
    
    </summary>
    
      <category term="ML" scheme="https://penglover.github.io/categories/ML/"/>
    
      <category term="TensorFlow" scheme="https://penglover.github.io/categories/ML/TensorFlow/"/>
    
    
      <category term="machinelearning" scheme="https://penglover.github.io/tags/machinelearning/"/>
    
      <category term="tensorflow" scheme="https://penglover.github.io/tags/tensorflow/"/>
    
  </entry>
  
  <entry>
    <title>머신러닝에서는 왜 시그모이드함수를 쓰는지 알아보자</title>
    <link href="https://penglover.github.io/2017/01/15/algorithm-sigmoid/"/>
    <id>https://penglover.github.io/2017/01/15/algorithm-sigmoid/</id>
    <published>2017-01-15T03:27:36.000Z</published>
    <updated>2017-01-15T08:48:31.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="why-sigmoid"><a href="#why-sigmoid" class="headerlink" title="why sigmoid"></a>why sigmoid</h1><p>머신러닝 알고리즘을 공부하다가보면 시그모이드 함수를 마주쳤을 것입니다.<br>그런데 이게 진짜 과연 써야하는 것인가?<br>그냥 linear한 함수를 쓰면 안되나?<br>이런 의문을 바로 해결해준 유투브 강의가 있어서 소개합니다.<br>김성훈님의 강의입니다.<br><div class="video-container"><iframe src="//www.youtube.com/embed/PIjno6paszY" frameborder="0" allowfullscreen></iframe></div></p>
<p>Logistic classification을 설명해 주시면서 등장합니다.<br>이런 이유라면 충분히 시그모이드 함수의 등장이 이해가 가네요!</p>
]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;why-sigmoid&quot;&gt;&lt;a href=&quot;#why-sigmoid&quot; class=&quot;headerlink&quot; title=&quot;why sigmoid&quot;&gt;&lt;/a&gt;why sigmoid&lt;/h1&gt;&lt;p&gt;머신러닝 알고리즘을 공부하다가보면 시그모이드 함수를 마주쳤을 
    
    </summary>
    
      <category term="ML" scheme="https://penglover.github.io/categories/ML/"/>
    
      <category term="algorithm" scheme="https://penglover.github.io/categories/ML/algorithm/"/>
    
    
      <category term="machinelearning" scheme="https://penglover.github.io/tags/machinelearning/"/>
    
      <category term="algorithm" scheme="https://penglover.github.io/tags/algorithm/"/>
    
  </entry>
  
  <entry>
    <title>텐서플로우할 때 txt파일을 쉽게 배열로 가져오는법(numpy)</title>
    <link href="https://penglover.github.io/2017/01/15/tensorflow-numpy/"/>
    <id>https://penglover.github.io/2017/01/15/tensorflow-numpy/</id>
    <published>2017-01-15T02:50:55.000Z</published>
    <updated>2017-01-15T04:01:23.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="numpy"><a href="#numpy" class="headerlink" title="numpy"></a>numpy</h1><p>파이썬에 기본 내장된 라이브러리로 따로 설치할 필요가 없습니다.<br>텐서플로우를 활용하다가 손쉽게 txt파일을 배열로 바꾸기 위해 찾은 라이브러리입니다.<br>예를들어 다음의 텐서플로우 코드를 보겠습니다.<br><figure class="highlight plain"><figcaption><span>multiple_variables.py</span></figcaption><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div></pre></td><td class="code"><pre><div class="line">import tensorflow as tf</div><div class="line">import numpy as np</div><div class="line"></div><div class="line">xy = np.loadtxt(&apos;input.txt&apos;, unpack=True, dtype=&apos;float32&apos;)</div><div class="line">x_data = xy[0:-1]</div><div class="line">y_data = xy[-1]</div><div class="line"></div><div class="line">W = tf.Variable(tf.random_uniform([1, len(x_data)], -1, 1))</div><div class="line">b = tf.Variable(tf.random_uniform([1], -1, 1))</div><div class="line"></div><div class="line">hypothesis = tf.matmul(W, x_data)</div><div class="line"></div><div class="line">cost = tf.reduce_mean(tf.square(hypothesis - y_data))</div><div class="line"></div><div class="line">a = tf.Variable(0.1)  # learning rate, alpha</div><div class="line">optimizer = tf.train.GradientDescentOptimizer(a)</div><div class="line">train = optimizer.minimize(cost)  # goal is minimize cost</div><div class="line"></div><div class="line">init = tf.global_variables_initializer()</div><div class="line"></div><div class="line">sess = tf.Session()</div><div class="line">sess.run(init)</div><div class="line">print(x_data)</div><div class="line">for step in range(2001):</div><div class="line">    sess.run(train)</div><div class="line">    if step % 200 == 0:</div><div class="line">        print (step, sess.run(cost), sess.run(W))</div><div class="line"></div></pre></td></tr></table></figure></p>
<p>input.txt는 다음과 같습니다.<br><figure class="highlight plain"><figcaption><span>input.txt</span></figcaption><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">#x0 x1 x2 y</div><div class="line">1   1   0   1</div><div class="line">1   0   2   2</div><div class="line">1   3   0   3</div><div class="line">1   0   4   4</div><div class="line">1   5   0   5</div></pre></td></tr></table></figure><br>numpy를 임포트 한 뒤에 loadtxt로 손쉽게 txt파일을 가져 올 수 있습니다.<br><figure class="highlight plain"><figcaption><span>numpy.py</span></figcaption><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">xy = np.loadtxt(&apos;input.txt&apos;, unpack=True, dtype=&apos;float32&apos;)</div></pre></td></tr></table></figure><br>그리고 다음과 같이 활용이 가능하지요.<br><figure class="highlight plain"><figcaption><span>numpy.py</span></figcaption><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">x_data = xy[0:-1]</div><div class="line">y_data = xy[-1]</div></pre></td></tr></table></figure></p>
<p>x_data는 그럼 다음과 같은 값으로 나오게 됩니다.<br>[[ 1.  1.  1.  1.  1.]<br> [ 1.  0.  3.  0.  5.]<br> [ 0.  2.  0.  4.  0.]]<br> 참 쉽죠?<br> 행과 열을 바꾸고 싶다면 transpose를 이용하면 쉽게 바꿀 수 있어요.<br> 자 그럼 이제부터 txt파일을 손쉽게 배열로 바꿔서 tensorflow에 적용할 수 있으실 것입니다.</p>
<p> 위의 코드 자체가 궁금하시다면<br> <a href="https://penglover.github.io/2017/01/15/how-to-handle-multiple-variables-in-tensorflow/">https://penglover.github.io/2017/01/15/how-to-handle-multiple-variables-in-tensorflow/</a><br> 이 포스팅을 봐주세요!</p>
]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;numpy&quot;&gt;&lt;a href=&quot;#numpy&quot; class=&quot;headerlink&quot; title=&quot;numpy&quot;&gt;&lt;/a&gt;numpy&lt;/h1&gt;&lt;p&gt;파이썬에 기본 내장된 라이브러리로 따로 설치할 필요가 없습니다.&lt;br&gt;텐서플로우를 활용하다가 손쉽게 tx
    
    </summary>
    
      <category term="ML" scheme="https://penglover.github.io/categories/ML/"/>
    
      <category term="TensorFlow" scheme="https://penglover.github.io/categories/ML/TensorFlow/"/>
    
    
      <category term="machinelearning" scheme="https://penglover.github.io/tags/machinelearning/"/>
    
      <category term="tensorflow" scheme="https://penglover.github.io/tags/tensorflow/"/>
    
  </entry>
  
  <entry>
    <title>텐서플로우 LinearRegression 변수가 여러가지인경우 대처법</title>
    <link href="https://penglover.github.io/2017/01/15/how-to-handle-multiple-variables-in-tensorflow/"/>
    <id>https://penglover.github.io/2017/01/15/how-to-handle-multiple-variables-in-tensorflow/</id>
    <published>2017-01-15T02:28:27.000Z</published>
    <updated>2017-01-15T04:01:19.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="텐서플로우에서-선형회귀함수-적용중-변수가-여러개라면"><a href="#텐서플로우에서-선형회귀함수-적용중-변수가-여러개라면" class="headerlink" title="텐서플로우에서 선형회귀함수 적용중 변수가 여러개라면?"></a>텐서플로우에서 선형회귀함수 적용중 변수가 여러개라면?</h1><p>보통 우리는 hypothesis = a <em> w </em> x + b<br>이 모델을 기본으로 삼았습니다.<br>x가 input이고 hypothesis는 기대값이죠.<br>a는 learning rate이고 w는 weight b는 bias 입니다.</p>
<p>그런데 사실 어떤 요인에게 영향을 주는 요소가 한개일 경우가 잘 없죠?<br>두개 이상인 경우에는 어떻게 모델링을 할까요?<br>아주 간단하게 이런 경우를 모델링 할 수 있습니다.<br>hypothesis = a<em> (w1</em>x1 + w2*x2) + b<br>위 처럼 적용하면 되는데요. 코드를 살피겠습니다.<br>코드는 위의 hypothesis를 배열 형태로 구현하였습니다.<br>input 데이터는<br><figure class="highlight plain"><figcaption><span>input.txt</span></figcaption><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">#x0 x1 x2 y</div><div class="line">1   1   0   1</div><div class="line">1   0   2   2</div><div class="line">1   3   0   3</div><div class="line">1   0   4   4</div><div class="line">1   5   0   5</div></pre></td></tr></table></figure></p>
<figure class="highlight plain"><figcaption><span>multiple_variables.py</span></figcaption><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div></pre></td><td class="code"><pre><div class="line">import tensorflow as tf</div><div class="line">import numpy as np</div><div class="line"></div><div class="line">xy = np.loadtxt(&apos;input.txt&apos;, unpack=True, dtype=&apos;float32&apos;)</div><div class="line">x_data = xy[0:-1]</div><div class="line">y_data = xy[-1]</div><div class="line"></div><div class="line">W = tf.Variable(tf.random_uniform([1, len(x_data)], -1, 1))</div><div class="line">b = tf.Variable(tf.random_uniform([1], -1, 1))</div><div class="line"></div><div class="line">hypothesis = tf.matmul(W, x_data)</div><div class="line"></div><div class="line">cost = tf.reduce_mean(tf.square(hypothesis - y_data))</div><div class="line"></div><div class="line">a = tf.Variable(0.1)  # learning rate, alpha</div><div class="line">optimizer = tf.train.GradientDescentOptimizer(a)</div><div class="line">train = optimizer.minimize(cost)  # goal is minimize cost</div><div class="line"></div><div class="line">init = tf.global_variables_initializer()</div><div class="line"></div><div class="line">sess = tf.Session()</div><div class="line">sess.run(init)</div><div class="line">print(x_data)</div><div class="line">for step in range(2001):</div><div class="line">    sess.run(train)</div><div class="line">    if step % 200 == 0:</div><div class="line">        print (step, sess.run(cost), sess.run(W))</div><div class="line"></div></pre></td></tr></table></figure>
<p><strong>결과값</strong><br>[[ 1.  1.  1.  1.  1.]<br> [ 1.  0.  3.  0.  5.]<br> [ 0.  2.  0.  4.  0.]]<br>0 0.43461 [[-0.20677651  1.29921687  1.09060895]]<br>200 5.33032e-08 [[ -5.47317148e-04   1.00014389e+00   1.00017071e+00]]<br>400 2.52953e-13 [[ -1.20747086e-06   1.00000036e+00   1.00000048e+00]]<br>600 1.77636e-14 [[ -2.96712130e-07   1.00000012e+00   1.00000012e+00]]<br>800 1.77636e-14 [[ -2.96712130e-07   1.00000012e+00   1.00000012e+00]]<br>1000 1.77636e-14 [[ -2.96712130e-07   1.00000012e+00   1.00000012e+00]]<br>1200 1.77636e-14 [[ -2.96712130e-07   1.00000012e+00   1.00000012e+00]]<br>1400 1.77636e-14 [[ -2.96712130e-07   1.00000012e+00   1.00000012e+00]]<br>1600 1.77636e-14 [[ -2.96712130e-07   1.00000012e+00   1.00000012e+00]]<br>1800 1.77636e-14 [[ -2.96712130e-07   1.00000012e+00   1.00000012e+00]]<br>2000 1.77636e-14 [[ -2.96712130e-07   1.00000012e+00   1.00000012e+00]]</p>
<p>간단하죠?<br>배열값은 순서대로 b, w1, w2입니다.<br>cost도 1.77636e-14로 거의 0에 가깝게 되었네요.<br>print(x_data)는 numpy 라이브러리가 어떤식으로 데이터를 가져와 주는지 알려주기 위해 넣어봤어요.<br>#부분은 무시를 한 채로 아래의 데이터를 행렬 형식으로 가져와줍니다.<br>numpy가 더 궁금하다면 다음 포스트를 봐주세요.</p>
<p>아주 쉽게 우리는 배열을 이용해서 weight를 추가시켰습니다.<br>질문이 있으면 댓글로 달아주세요!</p>
]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;텐서플로우에서-선형회귀함수-적용중-변수가-여러개라면&quot;&gt;&lt;a href=&quot;#텐서플로우에서-선형회귀함수-적용중-변수가-여러개라면&quot; class=&quot;headerlink&quot; title=&quot;텐서플로우에서 선형회귀함수 적용중 변수가 여러개라면?&quot;&gt;&lt;/a&gt;텐
    
    </summary>
    
      <category term="ML" scheme="https://penglover.github.io/categories/ML/"/>
    
      <category term="TensorFlow" scheme="https://penglover.github.io/categories/ML/TensorFlow/"/>
    
    
      <category term="machinelearning" scheme="https://penglover.github.io/tags/machinelearning/"/>
    
      <category term="tensorflow" scheme="https://penglover.github.io/tags/tensorflow/"/>
    
  </entry>
  
  <entry>
    <title>tensorflow에서 언제 LinearRegression을 적용시킬지 알아보는 법</title>
    <link href="https://penglover.github.io/2017/01/15/tensorflow-graph/"/>
    <id>https://penglover.github.io/2017/01/15/tensorflow-graph/</id>
    <published>2017-01-15T01:22:39.000Z</published>
    <updated>2017-01-15T04:00:15.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="LinearRegression은-언제-적용시킬까요"><a href="#LinearRegression은-언제-적용시킬까요" class="headerlink" title="LinearRegression은 언제 적용시킬까요?"></a>LinearRegression은 언제 적용시킬까요?</h1><p>이것을 알기 위해서는 그래프를 그려 보는 것이 좋습니다.<br>파이썬에서는 그래프를 쉽게 그리게 해주는 라이브러리가 존재하는데요~<br>바로 matplotlib를 이용하면 아주 쉽습니다.<br>pip이 설치되어 있다면 그냥 pip install matplotlib 하시면 됩니다.<br>python3버전이신 경우에는 pip3 install matplotlib를 하시구요.<br><a href="http://matplotlib.org/users/installing.html" rel="external nofollow noopener noreferrer" target="_blank">http://matplotlib.org/users/installing.html</a> 에서 다른 설치법들도 알려줍니다~<br>설치 안되시면 댓글남겨주세요.</p>
<p>그럼 코드를 보면서 설명드리도록 하겠습니다.<br><figure class="highlight plain"><figcaption><span>matplotlib.py</span></figcaption><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div></pre></td><td class="code"><pre><div class="line">import tensorflow as tf</div><div class="line">import matplotlib.pyplot as plt</div><div class="line"></div><div class="line">X = [1., 2., 3.]</div><div class="line">Y = [1., 2., 3.]</div><div class="line">m = samples = len(X)</div><div class="line"></div><div class="line">W = tf.placeholder(tf.float32)</div><div class="line"></div><div class="line">hypothesis = tf.mul(X, W)</div><div class="line"></div><div class="line">cost = tf.reduce_sum(tf.pow(hypothesis-Y,2))/m</div><div class="line"></div><div class="line">init = tf.global_variables_initializer()</div><div class="line"></div><div class="line"></div><div class="line">W_val = []</div><div class="line">cost_val = []</div><div class="line"></div><div class="line">sess = tf.Session()</div><div class="line">sess.run(init)</div><div class="line">for i in range(-30,50):</div><div class="line">    print (i*0.1, sess.run(cost, feed_dict=&#123;W: i*0.1&#125;))</div><div class="line">    W_val.append(i*0.1)</div><div class="line">    cost_val.append(sess.run(cost, feed_dict=&#123;W: i*0.1&#125;))</div><div class="line"></div><div class="line">plt.plot(W_val, cost_val, &apos;ro&apos;)</div><div class="line">plt.ylabel(&apos;cost&apos;)</div><div class="line">plt.xlabel(&apos;W&apos;)</div><div class="line">plt.show()</div></pre></td></tr></table></figure><br>결과값은 그래프가 포함되다보니 스크린샷으로 보여드리겠습니다.<br><img src="https://penglover.github.io/images/matplotlib_sample.png" alt="matplotlib_sample"></p>
<p>자 그럼 본격적인 이야기를 해보겠습니다.<br>코드는 참 평범합니다. 그냥 hypothesis-Y에 제곱을 한 값을 평균을 내어 준 것인데요.<br>우리는 이미 X와 Y의 관계가 X * 1 = Y라는 것을 알고 있습니다.<br>X = [1, 2, 3]이고 Y = [1, 2, 3]이니 당연한 일이지요.<br>컴퓨터를 통해서 그래프를 그려보도록 하겠습니다.<br>사용법은 코드를 조금만 보시면 이해가 쉽게 가실겁니다.</p>
<p>그림처럼 저렇게 순탄한 아래쪽이 둥근모형이면 손쉽게 LinearRegression을 적용할 수 있습니다.<br>기울기 값이 줄어들거나 늘어나는 패턴이 일정하기 때문이지요.<br>수식으로 순간미분값(해당 점의 기울기값)이 0에 가까워 지도록 찾아주기만 하면 되닌까요.</p>
<p>아주 간단하죠?<br>요약하자면 연속하고 아래쪽 둥근부분이 저렇게 그림처럼 한부분만 있으면 됩니다.<br>3차원의 경우에도 마찬가지에요!</p>
]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;LinearRegression은-언제-적용시킬까요&quot;&gt;&lt;a href=&quot;#LinearRegression은-언제-적용시킬까요&quot; class=&quot;headerlink&quot; title=&quot;LinearRegression은 언제 적용시킬까요?&quot;&gt;&lt;/a&gt;Line
    
    </summary>
    
      <category term="ML" scheme="https://penglover.github.io/categories/ML/"/>
    
      <category term="TensorFlow" scheme="https://penglover.github.io/categories/ML/TensorFlow/"/>
    
    
      <category term="machinelearning" scheme="https://penglover.github.io/tags/machinelearning/"/>
    
      <category term="tensorflow" scheme="https://penglover.github.io/tags/tensorflow/"/>
    
  </entry>
  
  <entry>
    <title>텐서플로우로 linear regression 구현 및 설명</title>
    <link href="https://penglover.github.io/2017/01/14/tf-LinearRegression/"/>
    <id>https://penglover.github.io/2017/01/14/tf-LinearRegression/</id>
    <published>2017-01-14T14:50:53.000Z</published>
    <updated>2017-01-15T04:00:17.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Linear-Regression"><a href="#Linear-Regression" class="headerlink" title="Linear Regression"></a>Linear Regression</h1><p>Linear Regression에 대한 지식이 없으시다면 아래의 동영상을 보시는 것을 추천합니다.<br><a href="https://www.youtube.com/watch?v=GmtqOlPYB84" rel="external nofollow noopener noreferrer" target="_blank">https://www.youtube.com/watch?v=GmtqOlPYB84</a><br>이미 알고 계신다면 렛츠고!<br>아! 참고로 tensorflow 버전이나 python버전이 다르다면<br>tf.global_variables_initializer, print, range 부분에 수정이 필요합니다.<br>오류나면 댓글남겨주세요 ㅎㅎ 바로 알려드릴게요.</p>
<figure class="highlight plain"><figcaption><span>LinearRegression.py</span></figcaption><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div></pre></td><td class="code"><pre><div class="line">import tensorflow as tf</div><div class="line"></div><div class="line">x_data = [1, 2, 3, 4]</div><div class="line">y_data = [2, 4, 6, 8]</div><div class="line"></div><div class="line">W = tf.Variable(tf.random_uniform([1], -10000, 10000))</div><div class="line">b = tf.Variable(tf.random_uniform([1], -10000, 10000))</div><div class="line"></div><div class="line">X = tf.placeholder(tf.float32)</div><div class="line">Y = tf.placeholder(tf.float32)</div><div class="line"></div><div class="line">hypothesis = W * X + b</div><div class="line"></div><div class="line">cost = tf.reduce_mean(tf.square(hypothesis - Y))</div><div class="line"></div><div class="line">a = tf.Variable(0.1)</div><div class="line">optimizer = tf.train.GradientDescentOptimizer(a)</div><div class="line">train = optimizer.minimize(cost)</div><div class="line"></div><div class="line">init = tf.global_variables_initializer()</div><div class="line"></div><div class="line">sess = tf.Session()</div><div class="line">sess.run(init)</div><div class="line"></div><div class="line">for step in range(2001):</div><div class="line">    sess.run(train, feed_dict=&#123;X: x_data, Y: y_data&#125;)</div><div class="line">    if step % 200 == 0:</div><div class="line">        print (step, sess.run(cost, feed_dict=&#123;X: x_data, Y: y_data&#125;), sess.run(W), sess.run(b))</div><div class="line"></div><div class="line">print (sess.run(hypothesis, feed_dict=&#123;X: [5, 10]&#125;))</div><div class="line">print (sess.run(hypothesis, feed_dict=&#123;X: [2.5, 1.5]&#125;))</div></pre></td></tr></table></figure>
<p><strong>결과값</strong><br>0 1.17541e+07 [-3064.45288086] [ 7678.85205078]<br>200 53.5173 [-4.08845949] [ 17.90081406]<br>400 0.000280612 [ 1.98605835] [ 0.04099015]<br>600 1.46635e-09 [ 1.99996805] [  9.38054509e-05]<br>800 1.42109e-14 [ 1.99999988] [  4.28800519e-07]<br>1000 0.0 [ 2.] [  1.18856534e-07]<br>1200 0.0 [ 2.] [  1.18856534e-07]<br>1400 0.0 [ 2.] [  1.18856534e-07]<br>1600 0.0 [ 2.] [  1.18856534e-07]<br>1800 0.0 [ 2.] [  1.18856534e-07]<br>2000 0.0 [ 2.] [  1.18856534e-07]<br>[ 10.  20.]<br>[ 5.  3.]</p>
<p>아주 쉽게 이해가 가실 것입니다.<br>W와 b를 -10000에서 10000사이의 랜덤한 값으로 두었습니다.<br>X와 Y는 32bit의 float형 데이터로 선언해 두었지요.<br>hypothesis는 input값이 될 X에게 w와 b를 더해서 나오는 결과에 대한 기대값입니다.<br>cost는 기대값과 실제값을 뺀것을 제곱을 한 것의 평균값을 갖게 될 것입니다.<br>reduce_mean은 참고로 평균값을 내게 해주는 매소드입니다.<br>(m개의 input이 있으면 그것들의 평균값을 매겨줌)<br>a는 learning rate입니다.<br>tf.train.GradientDescentOptimizer가 gradient descent 알고리즘을 처리해줍니다.<br>그리고 minimize가 cost를 인자로 받아서 train될때마다 W와 b를 업데이트합니다.<br>화면이 너무 꽉 찰 것 같아서 step은 200개당 1번 print 했습니다.<br>결과값을 보니 training이 아주 잘 되었네요!</p>
<p>헷갈리는 tensorflow의 링크가 있다면 아래에 모든 것이 나와있습니다.<br><a href="https://www.tensorflow.org/versions/master/api_docs/python/math_ops/reduction#reduce_mean" rel="external nofollow noopener noreferrer" target="_blank">https://www.tensorflow.org/versions/master/api_docs/python/math_ops/reduction#reduce_mean</a></p>
]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;Linear-Regression&quot;&gt;&lt;a href=&quot;#Linear-Regression&quot; class=&quot;headerlink&quot; title=&quot;Linear Regression&quot;&gt;&lt;/a&gt;Linear Regression&lt;/h1&gt;&lt;p&gt;Linear Reg
    
    </summary>
    
      <category term="ML" scheme="https://penglover.github.io/categories/ML/"/>
    
      <category term="TensorFlow" scheme="https://penglover.github.io/categories/ML/TensorFlow/"/>
    
    
      <category term="machinelearning" scheme="https://penglover.github.io/tags/machinelearning/"/>
    
      <category term="tensorflow" scheme="https://penglover.github.io/tags/tensorflow/"/>
    
  </entry>
  
  <entry>
    <title>텐서플로우에서 placeholder란 무엇일까?</title>
    <link href="https://penglover.github.io/2017/01/14/tf-placeholder/"/>
    <id>https://penglover.github.io/2017/01/14/tf-placeholder/</id>
    <published>2017-01-14T13:01:16.000Z</published>
    <updated>2017-01-15T04:00:19.000Z</updated>
    
    <content type="html"><![CDATA[<p>텐서플로우에서 참 재밌는 메서드가 있습니다.<br>바로 placeholder 인데요!<br>우리는 이것을 통해 값의 대입을 미룰 수 있습니다.<br>아래의 코드에서 자세히 확인해보겠습니다.<br>아! 참고로 python버전이 다르다면<br>print부분에 수정이 필요합니다.</p>
<figure class="highlight plain"><figcaption><span>placeholder.py</span></figcaption><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div></pre></td><td class="code"><pre><div class="line">import tensorflow as tf</div><div class="line"></div><div class="line">sess = tf.Session()</div><div class="line"></div><div class="line">a = tf.placeholder(tf.int16)</div><div class="line">b = tf.placeholder(tf.int16)</div><div class="line"></div><div class="line">add = tf.add(a, b)</div><div class="line">mul = tf.mul(a, b)</div><div class="line"></div><div class="line"></div><div class="line">print(&quot;더한 결과는 %i&quot; % sess.run(add,feed_dict=&#123;a: 2, b: 3&#125;))</div><div class="line">print(&quot;곱한 결과는 %i&quot; % sess.run(mul,feed_dict=&#123;a: 3, b: 4&#125;))</div></pre></td></tr></table></figure>
<p><strong>결과값</strong><br>더한 결과는 5<br>곱한 결과는 12</p>
<p>placeholder를 통해 먼저 16bit 크기의 int형 데이터의 공간을 만들어 놓았습니다.<br>그리고 나중에 연산을 할 때에 대입값을 지정해 주었지요.<br>나중에 아주 유용하게 많이 쓰이니 꼭 잘 숙지하고 넘어가야 하는 부분입니다.</p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;텐서플로우에서 참 재밌는 메서드가 있습니다.&lt;br&gt;바로 placeholder 인데요!&lt;br&gt;우리는 이것을 통해 값의 대입을 미룰 수 있습니다.&lt;br&gt;아래의 코드에서 자세히 확인해보겠습니다.&lt;br&gt;아! 참고로 python버전이 다르다면&lt;br&gt;pri
    
    </summary>
    
      <category term="ML" scheme="https://penglover.github.io/categories/ML/"/>
    
      <category term="TensorFlow" scheme="https://penglover.github.io/categories/ML/TensorFlow/"/>
    
    
      <category term="machinelearning" scheme="https://penglover.github.io/tags/machinelearning/"/>
    
      <category term="tensorflow" scheme="https://penglover.github.io/tags/tensorflow/"/>
    
  </entry>
  
  <entry>
    <title>텐서플로우에서 상수란 존재하지 않는다? 모든것은 연산!</title>
    <link href="https://penglover.github.io/2017/01/14/tensorflow1/"/>
    <id>https://penglover.github.io/2017/01/14/tensorflow1/</id>
    <published>2017-01-14T12:33:46.000Z</published>
    <updated>2017-01-15T04:00:17.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="텐서플로우에서-상수란-존재하지-않는다"><a href="#텐서플로우에서-상수란-존재하지-않는다" class="headerlink" title="텐서플로우에서 상수란 존재하지 않는다"></a>텐서플로우에서 상수란 존재하지 않는다</h1><figure class="highlight plain"><figcaption><span>NoConstant.py</span></figcaption><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div></pre></td><td class="code"><pre><div class="line">import tensorflow as tf</div><div class="line"></div><div class="line">sess = tf.Session()</div><div class="line"></div><div class="line">a = tf.constant(1)</div><div class="line">b = tf.constant(2)</div><div class="line"></div><div class="line">c = a+b</div><div class="line"></div><div class="line">print(a)</div><div class="line">print(b)</div><div class="line">print(c)</div><div class="line"></div><div class="line">print(sess.run(a))</div><div class="line">print(sess.run(b))</div><div class="line">print(sess.run(c))</div></pre></td></tr></table></figure>
<p><strong>결과값</strong><br>Tensor(“Const:0”, shape=(), dtype=int32)<br>Tensor(“Const_1:0”, shape=(), dtype=int32)<br>Tensor(“add:0”, shape=(), dtype=int32)<br>1<br>2<br>3</p>
<p>위에 보이듯이 모든 텐서플로우에서의 변수는 상수상태로 존재하지 않습니다.<br><strong>operation 상태로 존재하고 session에 run메소드를 주는 순간 연산이 이루어지지요.</strong><br>이로서 우리는 각 노드들을 병렬적으로 다룰 수 있게 되지요.<br>한마디로 각 노드들은 tensor들(데이터 배열들)을 나르는 역할을 할 뿐이기 때문에 모든 node는 operation이라고 하는 것이지요.<br>아래의 애니메이션을 보면 더 정확히 아실 수 있으실거에요!<br><img src="https://camo.githubusercontent.com/4ee55154486232ec9edd8f1a3bad4c4a146f6cfe/68747470733a2f2f7777772e74656e736f72666c6f772e6f72672f696d616765732f74656e736f72735f666c6f77696e672e676966" alt="움직이는텐서플로우그래프"></p>
]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;텐서플로우에서-상수란-존재하지-않는다&quot;&gt;&lt;a href=&quot;#텐서플로우에서-상수란-존재하지-않는다&quot; class=&quot;headerlink&quot; title=&quot;텐서플로우에서 상수란 존재하지 않는다&quot;&gt;&lt;/a&gt;텐서플로우에서 상수란 존재하지 않는다&lt;/h1&gt;&lt;
    
    </summary>
    
      <category term="ML" scheme="https://penglover.github.io/categories/ML/"/>
    
      <category term="TensorFlow" scheme="https://penglover.github.io/categories/ML/TensorFlow/"/>
    
    
      <category term="machinelearning" scheme="https://penglover.github.io/tags/machinelearning/"/>
    
      <category term="tensorflow" scheme="https://penglover.github.io/tags/tensorflow/"/>
    
  </entry>
  
  <entry>
    <title>텐서플로우란 무엇일까? 추천 설치방법</title>
    <link href="https://penglover.github.io/2017/01/14/What-is-tensorflow-How-to-install/"/>
    <id>https://penglover.github.io/2017/01/14/What-is-tensorflow-How-to-install/</id>
    <published>2017-01-14T10:21:32.000Z</published>
    <updated>2017-01-18T03:17:06.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="텐서플로우란-무엇일까"><a href="#텐서플로우란-무엇일까" class="headerlink" title="텐서플로우란 무엇일까"></a>텐서플로우란 무엇일까</h1><p>요새 굉장히 핫하죠! 머신러닝, 딥러닝!<br>(머신러닝과 딥러닝에 대한 설명은 다음에 포스팅을 따로 하겠습니다)<br>텐서플로우는 구글에서 발표한 딥러닝 프레임워크입니다.<br>간편하게 딥러닝 코드를 짜도록 도와주지요.<br>그렇다면 텐서플로우는 왜 텐서플로우일까요?<br>텐서는 다차원의 배열을 가르킵니다.<br>플로우는 그 배열의 이동을 표현하는 말이지요.<br>다차원 배열들이 그래프에서 이동한다고 해서 텐서플로우라고 이름을 붙였답니다.<br>좀더 이해를 돕기 위해 텐서플로우를 이용해 코딩하는 방식을 설명드리겠습니다.<br>operation들을 우선 정의합니다.<br>이 op들은 계산을 수행하고 결과를 하나 이상의 텐서로 반환할 수 있습니다.<br>텐서는 일종의 다차원 배열이며 데이터의 표현방식일 뿐입니다.<br>그리고 op들이 계산을 수행하고 결과를 반환하며 나아가는 과정은 그래프에서 이루어지는데요!<br>이 그래프를 실행하기 위해서는 세션 객체가 필요합니다.<br>한마디로 op들이 계산을 수행하고 tensor들이 op에 의해 반환되는 일련의 과정들을 session을 통해 캡슐화 한 것이라고 할 수 있습니다.</p>
<h1 id="텐서플로우의-특징"><a href="#텐서플로우의-특징" class="headerlink" title="텐서플로우의 특징"></a>텐서플로우의 특징</h1><p>텐서플로우는 구글에서 발표한 머신러닝 오픈소스 라이브러리로 내부는 C++로 되어있고 여러 언어의 API를 제공합니다.<br>가장 문서화가 잘 되어있고 인기있는 API는 파이썬입니다.<br>때문에 주로 사람들이 파이썬으로 개발을 하는데요!<br>그렇다면 왜 텐서플로우가 핫할까요?<br>그것은 바로 텐서플로우를 이용하면 짧은 시간에 강력한 머신러닝, 딥러닝 코드를 짤 수 있기 때문입니다.<br>테스트할 때에 쓰기도 좋고 상용 시스템을 만들 때에도 좋은 라이브러리입니다.</p>
<h1 id="텐서플로우는-왜-빠를까"><a href="#텐서플로우는-왜-빠를까" class="headerlink" title="텐서플로우는 왜 빠를까"></a>텐서플로우는 왜 빠를까</h1><p>텐서플로우가 빠른데에는 이유가 있습니다.<br><img src="https://penglover.github.io/images/tensorflow_howtowork.png" alt="텐서플로우작동방식"><br>위의 그림에서 보시다시피 각각의 node들이 연산을 병렬적으로 처리합니다.<br>내부코드가 C++라서 빠른데다가 병렬성이 좋아서 여기저기 잘 붙습니다.<br>즉 굉장히 유연하게 cpu, gpu 등의 환경에서 빠르게 처리될 수 있습니다.</p>
<h1 id="텐서플로우-설치방법"><a href="#텐서플로우-설치방법" class="headerlink" title="텐서플로우 설치방법"></a>텐서플로우 설치방법</h1><blockquote><p>아래의 링크에 설치 방법이 자세히 나와있습니다. 가장 추천하는 방법은 Virtualenv 설치입니다. 이유는 가상환경을 이용함으로써 파이썬의 버전을 독립적으로 지켜주기 때문입니다.</p>
<footer><strong>@텐서플로우설치</strong><cite><a href="https://tensorflowkorea.gitbooks.io/tensorflow-kr/content/g3doc/get_started/os_setup.html" rel="external nofollow noopener noreferrer" target="_blank">tensorflowkorea.gitbooks.io/tensorflow-kr/content/g3doc/get_started/os_setup.html</a></cite></footer></blockquote>
<p>혹시 설치방법에 문제가 생긴 경우에는 댓글로 문의를 주세요!</p>
]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;텐서플로우란-무엇일까&quot;&gt;&lt;a href=&quot;#텐서플로우란-무엇일까&quot; class=&quot;headerlink&quot; title=&quot;텐서플로우란 무엇일까&quot;&gt;&lt;/a&gt;텐서플로우란 무엇일까&lt;/h1&gt;&lt;p&gt;요새 굉장히 핫하죠! 머신러닝, 딥러닝!&lt;br&gt;(머신러닝과 딥
    
    </summary>
    
      <category term="ML" scheme="https://penglover.github.io/categories/ML/"/>
    
      <category term="TensorFlow" scheme="https://penglover.github.io/categories/ML/TensorFlow/"/>
    
    
      <category term="machinelearning" scheme="https://penglover.github.io/tags/machinelearning/"/>
    
      <category term="tensorflow" scheme="https://penglover.github.io/tags/tensorflow/"/>
    
  </entry>
  
  <entry>
    <title>텐서플로우 무료강의 소개</title>
    <link href="https://penglover.github.io/2017/01/14/tensorflow-lecture-korean/"/>
    <id>https://penglover.github.io/2017/01/14/tensorflow-lecture-korean/</id>
    <published>2017-01-14T08:24:28.000Z</published>
    <updated>2017-01-15T04:00:16.000Z</updated>
    
    <content type="html"><![CDATA[<p>머신러닝에서 가장 핫한 라이브러리중 하나죠! tensorflow!<br>그런데 아직 한글로 된 강의가 많이 없는 것이 현실입니다.<br><strong>홍콩 과학기술대학교의 김성훈 교수님이 tensorflow를 무료로 강의해주십니다.</strong><br>대상은 비전공자나 전공자 중에서 머신러닝 입문자들입니다. ㅎㅎ<br>정말 기초부터 차근차근 잘 알려주십니다.<br><a href="https://hunkim.github.io/ml/" rel="external nofollow noopener noreferrer" target="_blank">https://hunkim.github.io/ml/</a><br>다음의 링크를 타고 가시면 강의를 볼 수 있습니다~^^</p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;머신러닝에서 가장 핫한 라이브러리중 하나죠! tensorflow!&lt;br&gt;그런데 아직 한글로 된 강의가 많이 없는 것이 현실입니다.&lt;br&gt;&lt;strong&gt;홍콩 과학기술대학교의 김성훈 교수님이 tensorflow를 무료로 강의해주십니다.&lt;/strong
    
    </summary>
    
      <category term="ML" scheme="https://penglover.github.io/categories/ML/"/>
    
      <category term="TensorFlow" scheme="https://penglover.github.io/categories/ML/TensorFlow/"/>
    
    
      <category term="machinelearning" scheme="https://penglover.github.io/tags/machinelearning/"/>
    
      <category term="tensorflow" scheme="https://penglover.github.io/tags/tensorflow/"/>
    
  </entry>
  
</feed>
