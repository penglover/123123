<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>IT&#39;s IT Blog</title>
  <subtitle>Penglover&#39;s Software house</subtitle>
  <link href="/feed.xml" rel="self"/>
  
  <link href="https://penglover.github.io/"/>
  <updated>2017-01-19T07:55:08.000Z</updated>
  <id>https://penglover.github.io/</id>
  
  <author>
    <name>Myeongsoo Kim</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>텐서 플로우의 기본 사용법 정리 이건알고가셔야합니다!</title>
    <link href="https://penglover.github.io/2017/01/19/tf-basic-usage/"/>
    <id>https://penglover.github.io/2017/01/19/tf-basic-usage/</id>
    <published>2017-01-19T06:24:51.000Z</published>
    <updated>2017-01-19T07:55:08.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="개요"><a href="#개요" class="headerlink" title="개요"></a>개요</h1><p>이전 시간에 텐서플로우가 무엇인지, 어떻게 설치하는지를 보았습니다.<br><a href="https://penglover.github.io/2017/01/14/What-is-tensorflow-How-to-install/">https://penglover.github.io/2017/01/14/What-is-tensorflow-How-to-install/</a><br>오늘은 그렇다면 기본적인 사용법에 대한 정리를 해보겠습니다.<br>우선 지난시간에 말씀드렸듯이 텐서플로우란 op들이 계산을 수행하고 tensor들이 작업(op)에 의해 반환되는 일련의 과정들을 session을 통해 캡슐화 한 것이라고 할 수 있습니다.<br>순서대로 좀더 일목요연하게 나타내면 아래와 같습니다.</p>
<ol>
<li>graph를 조립하는 구성단계를 갖습니다.<br>작업(op)들을 반환될 데이터(tensor)를 고려하여 구성합니다.</li>
<li>graph의 op를 실행시키는 실행단계를 갖습니다.<br>그래프는 연산을 표현해 놓은 것이기 때문에 session상에서 실행시켜야 합니다.<br>session은 CPU나 GPU같은 Device에 배정하고 실행하기 위한 매서드를 제공합니다.</li>
</ol>
<h1 id="언어"><a href="#언어" class="headerlink" title="언어"></a>언어</h1><p>현재 공식적으로 지원하는 것은 cpp와 python이지만 점차 확대해나가겠다고 합니다.<br>문서화가 가장 잘 되어있고 사용하기 편한것은 python으로 대부분 python을 이용해 개발합니다.<br>또한 파이썬의 문법이 공부하기가 더 쉽고 헬퍼함수도 더 많아서 추천드립니다.</p>
<h1 id="전체적인-코드-주석해설"><a href="#전체적인-코드-주석해설" class="headerlink" title="전체적인 코드 + 주석해설"></a>전체적인 코드 + 주석해설</h1><figure class="highlight plain"><figcaption><span>code.py</span></figcaption><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line">import tensorflow as tf #텐서플로우를 불러옵니다.</div><div class="line">matrix1 = tf.constant([[3., 3.]]) # 1x2행렬지정</div><div class="line">matrix2 = tf.constant([[2.],[2.]]) # 2x1행렬지정</div><div class="line">product = tf.matmul(matrix1, matrix2) # 두 행렬을 곱해줍니다.</div><div class="line">sess = tf.Session() # defualt graph의 세션만듭니다.</div><div class="line">result = sess.run(product) # 위의 세션을 실행시킵니다.</div><div class="line">print(result) # 결과를 보여줍니다.</div><div class="line">sess.close() # 연산에 쓰인 시스템 자원을 반환해줍니다.</div></pre></td></tr></table></figure>
<h1 id="세션지정"><a href="#세션지정" class="headerlink" title="세션지정"></a>세션지정</h1><figure class="highlight plain"><figcaption><span>session.py</span></figcaption><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">with tf.Session() as sess:</div><div class="line">  with tf.device(&quot;/gpu:1&quot;):</div><div class="line">    matrix1 = tf.constant([[3., 3.]])</div><div class="line">    matrix2 = tf.constant([[2.],[2.]])</div><div class="line">    product = tf.matmul(matrix1, matrix2)</div><div class="line">    ...</div></pre></td></tr></table></figure>
<p>이런식으로 gpu가 여러개라면 따로따로 지정해 줄수도 있습니다.<br>“/cpu:0”: 컴퓨터의 CPU.<br>“/gpu:0”: 컴퓨터의 1번째 GPU.<br>“/gpu:1”: 컴퓨터의 2번쨰 GPU.<br>이런식입니다.</p>
<h1 id="클러스터도-만들-수-있습니다"><a href="#클러스터도-만들-수-있습니다" class="headerlink" title="클러스터도 만들 수 있습니다."></a>클러스터도 만들 수 있습니다.</h1><p>클러스터란 여러대의 컴퓨터를 모아서 하나의 컴퓨터처럼 동작시키는 것을 말합니다.<br><figure class="highlight plain"><figcaption><span>cluster.py</span></figcaption><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line"># 1번코드</div><div class="line">with tf.Session(&quot;grpc://example.org:2222&quot;) as sess:</div><div class="line">--------------------------------------------------</div><div class="line"># 2번코드</div><div class="line">with tf.device(&quot;/job:ps/task:0&quot;):</div><div class="line">  weights = tf.Variable(...)</div><div class="line">  biases = tf.Variable(...)</div></pre></td></tr></table></figure><br>1번코드처럼 각 머신에 텐서플로우 서버를 설치하고 session을 머신의 네트워크 위치로 넘기면 됩니다.<br>세션을 받은 머신은 해당 Session의 마스터가 됩니다.<br>머신 내에서는 Tensorflow의 구현 코드(implementation)가 머신 내 연산 자원에게 작업을 나눠주지만, 클러스터에서는 마스터가 클러스터 내의 다른 머신들에게 graph를 분배하는 것입니다.<br>2번코드처럼 “with tf.device():” 구문을 이용해서 특정 머신에게 직접 graph의 특정 부분을 지정해 줄 수도 있습니다.</p>
<h1 id="Tensor란"><a href="#Tensor란" class="headerlink" title="Tensor란?"></a>Tensor란?</h1><p>tensor를 n 차원의 배열이나 리스트라고 봐도 좋습니다.<br>작업(op)들간에는 tensor만 주고 받을 수 있습니다.<br>나중에 다루겠지만 이 tensor도 상당히 중요한 역할을 합니다만 지금은 데이터정도로만 봐주세요!</p>
<h1 id="Variable란"><a href="#Variable란" class="headerlink" title="Variable란?"></a>Variable란?</h1><p>변수(Variable) 를 생성할 때 Variable() 생성자의 초기값으로 Tensor 를 전달받게 됩니다.<br>TensorFlow는 상수(constants) 또는 임의(random)의 값 으로 초기화 하는 다양한 명령어(op)를 제공합니다.<br><figure class="highlight plain"><figcaption><span>variable.py</span></figcaption><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">weights = tf.Variable(tf.random_normal([784, 200], stddev=0.35), name=&quot;weights&quot;)</div><div class="line">biases = tf.Variable(tf.zeros([200]), name=&quot;biases&quot;)</div></pre></td></tr></table></figure><br>무슨 뜻인지는 아직 모르셔도 됩니다.<br>그냥 variable이 tensor를 전달받을 수 있구나~ 그리고 tensorflow에서는 variable을 다양한 방법으로 초기화하는 방법을 제공하는구나~ 정도로만 아셔도 되요!</p>
<h1 id="Feed란"><a href="#Feed란" class="headerlink" title="Feed란?"></a>Feed란?</h1><p>우선 이런걸 나중에 선언할거야~ 라고 지정하고 난 뒤에 일시적으로 연산의 출력값을 입력한 tensor 값으로 대체합니다. feed 데이터는 run()으로 전달되어서 run()의 변수로만 사용됩니다.<br>가장 일반적인 사용방법은 tf.placeholder()를 사용해서 특정 작업(op)을 “feed” 작업으로 지정해 주는 것입니다.<br>예시는 아래와 같습니다.<br><figure class="highlight plain"><figcaption><span>feed.py</span></figcaption><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">input1 = tf.placeholder(tf.float32)</div><div class="line">input2 = tf.placeholder(tf.float32)</div><div class="line">output = tf.mul(input1, input2)</div><div class="line"></div><div class="line">with tf.Session() as sess:</div><div class="line">  print(sess.run([output], feed_dict=&#123;input1:[7.], input2:[2.]&#125;))</div></pre></td></tr></table></figure><br>이렇게 우리는 input1과 input2의 형만 지정해 두고 일시적으로 나중에 값을 줄 수가 있는 것입니다.</p>
]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;개요&quot;&gt;&lt;a href=&quot;#개요&quot; class=&quot;headerlink&quot; title=&quot;개요&quot;&gt;&lt;/a&gt;개요&lt;/h1&gt;&lt;p&gt;이전 시간에 텐서플로우가 무엇인지, 어떻게 설치하는지를 보았습니다.&lt;br&gt;&lt;a href=&quot;https://penglover.gi
    
    </summary>
    
      <category term="ML" scheme="https://penglover.github.io/categories/ML/"/>
    
      <category term="TensorFlow" scheme="https://penglover.github.io/categories/ML/TensorFlow/"/>
    
    
      <category term="machinelearning" scheme="https://penglover.github.io/tags/machinelearning/"/>
    
  </entry>
  
  <entry>
    <title>직접체험&gt;&gt;여드름없애기1번째 - 피부재생편(잠, 음식)</title>
    <link href="https://penglover.github.io/2017/01/19/face-pimple/"/>
    <id>https://penglover.github.io/2017/01/19/face-pimple/</id>
    <published>2017-01-19T04:57:23.000Z</published>
    <updated>2017-01-19T05:19:26.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="여드름은-왜생길까"><a href="#여드름은-왜생길까" class="headerlink" title="여드름은 왜생길까?"></a>여드름은 왜생길까?</h1><p>여드름의 근본적인 원인, 즉 모공이 막히는 원인에 대해서는 아직 명확하게 밝혀진 바는 없다고합니다.<br>피부의학계에서는 현재까지 가장 유력한 원인으로 유전을 꼽고 있습니다.<br>피지가 적절히 생성되는 사람들이 있는가 하면 어떤 사람들은 피지가 과분비되는 유전자를 보유하고 있다는 것입니다.</p>
<h1 id="어떻게-여드름을-없애지"><a href="#어떻게-여드름을-없애지" class="headerlink" title="어떻게 여드름을 없애지?"></a>어떻게 여드름을 없애지?</h1><p>의학적으로 원인이 아직 명확하지 않다보니 고민을 많이했습니다.<br>그러다가 제가 한 생각은 ‘적당히 익으면 뽑고 피부재생이 원활히 되도록 하자’입니다.<br>안익은 것이 터지면 더 심해진다고 해서 완전히 익은것만 뽑기로 했습니다.<br>뽑는 것은 간단하게 집에 있는 면봉으로 하기로 했습니다.<br>그리고 피부재생에 대해 열심히 구글링해본 결과 10시부터 재생을 돕는 호르몬이 나오므로 10시에 취침을 하기로 결정했습니다.<br>수면시간은 7~8시간이 적절하다는 의견에 따라 6시에 알람을 맞추었습니다.<br>음식으로는 양배추, 파프리카, 시금치, 당근, 버섯, 브로콜리, 토마토, 블루베리, 사과 등이 피부재생을 돕는다고 합니다<br>&lt;관련 링크&gt;<br><a href="http://blog.daum.net/_blog/BlogTypeView.do?blogid=0UXGk&amp;articleno=46&amp;categoryId=6&amp;regdt=20100912155907" rel="external nofollow noopener noreferrer" target="_blank">http://blog.daum.net/_blog/BlogTypeView.do?blogid=0UXGk&amp;articleno=46&amp;categoryId=6&amp;regdt=20100912155907</a><br><a href="http://blog.daum.net/yho9721/128" rel="external nofollow noopener noreferrer" target="_blank">http://blog.daum.net/yho9721/128</a><br>따라서 매일 의식적으로 저기 적힌 음식들중 한가지 이상을 먹기로 했습니다.<br>이것을 하며 최소 1주일 최대 2주일까지 매일 사진을 찍으며 실제 효능성을 따져보기로 했습니다.<br>(과학적으로 증명된 것이 없으니 직접 실험해봐야죠 ㅠㅠ)</p>
<h1 id="결과"><a href="#결과" class="headerlink" title="결과"></a>결과</h1><p>1일차입니다.<br><img src="https://penglover.github.io/images/face1.jpeg" alt="day1"><br>화질이 안좋아서 잘 안보이는군요.<br>실제로는 색이 사진보다 좀 더 진합니다.<br>저런것들이 이마부터 목 부근까지 덮여있습니다 ㅠㅠ<br>이제 시작이니 힘내야지요!</p>
]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;여드름은-왜생길까&quot;&gt;&lt;a href=&quot;#여드름은-왜생길까&quot; class=&quot;headerlink&quot; title=&quot;여드름은 왜생길까?&quot;&gt;&lt;/a&gt;여드름은 왜생길까?&lt;/h1&gt;&lt;p&gt;여드름의 근본적인 원인, 즉 모공이 막히는 원인에 대해서는 아직 명확하게
    
    </summary>
    
      <category term="PRIVATE" scheme="https://penglover.github.io/categories/PRIVATE/"/>
    
      <category term="Face" scheme="https://penglover.github.io/categories/PRIVATE/Face/"/>
    
    
      <category term="face" scheme="https://penglover.github.io/tags/face/"/>
    
      <category term="pimple" scheme="https://penglover.github.io/tags/pimple/"/>
    
  </entry>
  
  <entry>
    <title>웹 에디터 아톰 추천 및 권장 패키지</title>
    <link href="https://penglover.github.io/2017/01/18/atom-editor/"/>
    <id>https://penglover.github.io/2017/01/18/atom-editor/</id>
    <published>2017-01-18T05:43:08.000Z</published>
    <updated>2017-01-18T05:55:37.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="에디터란-어떤-기능을-할까"><a href="#에디터란-어떤-기능을-할까" class="headerlink" title="에디터란 어떤 기능을 할까?"></a>에디터란 어떤 기능을 할까?</h1><p>아톰이 에디터이므로 에디터에 대한 말씀을 먼저 드려야 할 것 같습니다.<br>물론 메모장으로 작업을 해도 html문서를 만들 수 있기는 합니다.<br>하지만 이를 더 효율적으로 도와주기 위해 나온 개념이 에디터입니다.<br>문법의 오류를 잡아주고 자동완성을 시켜주면서 우리를 도와주지요.</p>
<h1 id="아톰을-추천하는-이유"><a href="#아톰을-추천하는-이유" class="headerlink" title="아톰을 추천하는 이유?"></a>아톰을 추천하는 이유?</h1><p>우선 무료인 것이 큰 장점입니다.<br>누구나 atom.io에 접속해서 설치를 할 수 있습니다.<br>그리고 유저층이 두껍고 개발이 아직도 활발히 진행되고 있습니다.<br>편집기의 기본 성능도 훌륭한 편이며 많은 패키지들이 활발하게 개발되고 있어서 우리가 원하는 기능을 가져다가 쓰기 쉽습니다.</p>
<h1 id="추천-패키지"><a href="#추천-패키지" class="headerlink" title="추천 패키지?"></a>추천 패키지?</h1><p>minimap : 우측에 코드를 썸네일 형식으로 대략적으로 보여줘서 편합니다.<br>emmet : 코드의 자동완성을 돕습니다.<br>active-power-mode : 코딩하면 이펙트가 나와서 재밌습니다.<br>linter : 코드의 오류를 잡아줍니다.(linter-jshint, linter-csslint)<br>highlight-selected : 같은 단어를 네모로 표시해줘서 쉽게 알아보도록 도와줍니다.<br>atom-minify : js파일과 css파일을 min사이즈로 압축해줍니다.<br>sublime-style-column-selction : 알트를 누르고 세로로 드래그가 가능하도록 해줍니다.</p>
]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;에디터란-어떤-기능을-할까&quot;&gt;&lt;a href=&quot;#에디터란-어떤-기능을-할까&quot; class=&quot;headerlink&quot; title=&quot;에디터란 어떤 기능을 할까?&quot;&gt;&lt;/a&gt;에디터란 어떤 기능을 할까?&lt;/h1&gt;&lt;p&gt;아톰이 에디터이므로 에디터에 대한 말
    
    </summary>
    
      <category term="WEB" scheme="https://penglover.github.io/categories/WEB/"/>
    
      <category term="Other" scheme="https://penglover.github.io/categories/WEB/Other/"/>
    
    
      <category term="web" scheme="https://penglover.github.io/tags/web/"/>
    
  </entry>
  
  <entry>
    <title>자바스크립트를 빠르고 효율적으로 공부하는 방법</title>
    <link href="https://penglover.github.io/2017/01/18/js-tutorial1/"/>
    <id>https://penglover.github.io/2017/01/18/js-tutorial1/</id>
    <published>2017-01-18T04:35:31.000Z</published>
    <updated>2017-01-19T05:17:39.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="자바스크립트란"><a href="#자바스크립트란" class="headerlink" title="자바스크립트란?"></a>자바스크립트란?</h1><p>자바스크립트는 프론트엔드와 백엔드에서 둘다 쓰이는 만능의 웹 언어입니다.<br>본래 넷스케이프의 브랜든 아이히에 의해 모카라는 이름으로 만들어졌습니다.<br>모카는 곧 라이브 스크립트라는 이름으로 개발됐고, 이후 넷스케이프가 썬 마이크로시스템과 함께 라이브 스크립트에 자바스크립트라는 이름을 붙이고 본격적으로 발전하기 시작한 언어입니다.<br>저는 오늘은 프론트엔드쪽을 부각시켜 설명해보려 합니다.<br>자바스크립트는 주로 웹페이지를 동적으로 만들어주기 위해서 사용됩니다.<br>웹에서 그림도 그려주고, 게임도 만들 수 있게 해주지요.(심지어는 3D도 가능!)<br>이미지가 시간별로 변하도록 만들어주기도 하는가 하면 팝업창도 띄워줍니다.<br>이런식으로 웹에서 동적으로 변하는 것을 담당하는 녀석인데요!<br>이런 이유로 프론트엔드에서는 주로 HTML+CSS+JAVASCRIPT로 개발을 합니다.<br>선행지식으로는 HTML과 CSS가 있습니다.<br>제 이전글을 참고해주세요!</p>
<h1 id="JQUERY란"><a href="#JQUERY란" class="headerlink" title="JQUERY란?"></a>JQUERY란?</h1><p>자바스크립트는 주로 JQUERY라는 아이와 함께 쓰입니다.<br>JQUERY는 이런 자바스크립트를 더 편하게 쓰게 해주기 위해 태어난 라이브러리이지요.<br>물론 코드가 더러워진다고 싫어하는 분들도 많지만 여전히 대다수의 웹사이트가 JQUERY의 도움을 받아 탄생하고 있는 만큼 익혀두시는게 좋습니다.<br>또한 JQUERY MOBILE을 이용하여 모바일 웹사이트도 손쉽게 만들수 있도록 도와줍니다.<br>써보시면 이런 신세계가?? 하실겁니다 ㅎㅎ</p>
<h1 id="어떻게-공부할까"><a href="#어떻게-공부할까" class="headerlink" title="어떻게 공부할까?"></a>어떻게 공부할까?</h1><p>자바스크립트 관련 무료강의는 매우 많습니다.<br>하지만 자바스크립트는 html과 css와는 다르게 코딩 스타일이라는 것이 좀 사람마다 편차가 심하게 다른 언어입니다.<br>따라서 여러 사이트들을 전전하며 익히는 것보다 좋은 책 한권을 잡고 익히는것을 추천합니다.<br>현재 추천하는 책은 모던웹을 위한 javascript+jquery입문 입니다.<br>이 책을 읽고 나머지는 w3schools.com에서 레퍼런스를 읽으며 개발에서 그때그때 필요한 기능들을 익히는 편이 좋습니다.<br>아니면 이책 말고도 네이버 서적에서 javascript 친다음에 순위별로 정렬해서 1위인 책을 읽는 것도 좋은 선택일것 같습니다!</p>
]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;자바스크립트란&quot;&gt;&lt;a href=&quot;#자바스크립트란&quot; class=&quot;headerlink&quot; title=&quot;자바스크립트란?&quot;&gt;&lt;/a&gt;자바스크립트란?&lt;/h1&gt;&lt;p&gt;자바스크립트는 프론트엔드와 백엔드에서 둘다 쓰이는 만능의 웹 언어입니다.&lt;br&gt;본래 넷
    
    </summary>
    
      <category term="WEB" scheme="https://penglover.github.io/categories/WEB/"/>
    
      <category term="Javascript" scheme="https://penglover.github.io/categories/WEB/Javascript/"/>
    
    
      <category term="web" scheme="https://penglover.github.io/tags/web/"/>
    
      <category term="javascript" scheme="https://penglover.github.io/tags/javascript/"/>
    
  </entry>
  
  <entry>
    <title>CSS3을 빠르고 효율적으로 공부하는 방법</title>
    <link href="https://penglover.github.io/2017/01/18/CSS3-tutorial1/"/>
    <id>https://penglover.github.io/2017/01/18/CSS3-tutorial1/</id>
    <published>2017-01-18T04:06:17.000Z</published>
    <updated>2017-01-18T04:34:29.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="css란-무엇"><a href="#css란-무엇" class="headerlink" title="css란 무엇?"></a>css란 무엇?</h1><p>css는 html의 형제라고 볼 수 있습니다.<br>html이 문서의 구조를 설계해주면 css가 그것을 꾸며주는 것이지요.<br>우리가 실제로 보는 문서는 css가 없다면 그냥 줄글형태일 것입니다.<br>우리가 편하게 웹을 사용할 수 있는 것은 어쩌면 css의 덕이 가장 크지요!<br>공부하기 위해서는 html의 지식이 선행되어야 합니다.<br>(제 이전 포스팅이 HTML5 포스팅이었습니다 ㅎㅎ 참고하세용)</p>
<h1 id="CSS3이란-무엇"><a href="#CSS3이란-무엇" class="headerlink" title="CSS3이란 무엇?"></a>CSS3이란 무엇?</h1><p>기존의 css는 아무래도 자바스크립트나 기타 플러그인에 많이 의지할 수 밖에 없었습니다.<br>우리는 동적인 웹사이트를 원하지만 css로만 코딩을 한다면 웹사이트는 너무 정적이기 때문이지요.<br>이러한 한계를 깨고있는 가장 최신버전의 css가 바로 CSS3입니다.<br>이미지가 왔다갔다 한다던가 자동으로 크기조절이 된다던가 하는 것들이 가능하게 됩니다.<br>심지어는 3차원적으로도 활용이 가능해서 매우 동적으로 변한것이 포인트입니다.<br>하지만 HTML5와 마찬가지로 구형브라우저에 대한 지원이 미미합니다.<br>그래서 자신의 타겟들의 연령대가 높거나 공공기관을 대상으로 한다면 CSS3의 최신기술들은 미뤄두는 것이 좋을수도 있습니다.<br>하지만 트렌디한 웹을 만들고 싶다면 도전해보세요!</p>
<h1 id="추천-공부방식은"><a href="#추천-공부방식은" class="headerlink" title="추천 공부방식은?"></a>추천 공부방식은?</h1><p>opentutorials.org에서 css강의를 우선 듣는 것을 추천합니다.<br>그리고 w3schools.com에서 튜토리얼을 진행해보세요.<br>그 후 마지막으로 서점에 가서 가능한 최신의 css3서적을 한권정도 읽으시면 됩니다.<br>그 이후에는 개발을 하다가 모르는 것이 나온다면 w3schools의 레퍼런스를 뒤지면서 하신다면 무리없이 개발이 가능할겁니다!</p>
]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;css란-무엇&quot;&gt;&lt;a href=&quot;#css란-무엇&quot; class=&quot;headerlink&quot; title=&quot;css란 무엇?&quot;&gt;&lt;/a&gt;css란 무엇?&lt;/h1&gt;&lt;p&gt;css는 html의 형제라고 볼 수 있습니다.&lt;br&gt;html이 문서의 구조를 설계해주면
    
    </summary>
    
      <category term="WEB" scheme="https://penglover.github.io/categories/WEB/"/>
    
      <category term="HTML/CSS" scheme="https://penglover.github.io/categories/WEB/HTML-CSS/"/>
    
    
      <category term="web" scheme="https://penglover.github.io/tags/web/"/>
    
      <category term="css" scheme="https://penglover.github.io/tags/css/"/>
    
  </entry>
  
  <entry>
    <title>HTML5를 효율적으로 빠르게 공부하는 방법</title>
    <link href="https://penglover.github.io/2017/01/18/HTML5-tutorial1/"/>
    <id>https://penglover.github.io/2017/01/18/HTML5-tutorial1/</id>
    <published>2017-01-18T03:30:44.000Z</published>
    <updated>2017-01-18T04:34:27.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="HTML이란-무엇"><a href="#HTML이란-무엇" class="headerlink" title="HTML이란 무엇?"></a>HTML이란 무엇?</h1><p>우선 html이야기를 하기 이전에 웹 이야기를 빼놓을 수가 없군요.<br>우리는 웹을 항상 접하며 삽니다.<br>네이버 다음 이런것들이 웹사이트들이닌깐요.<br>그렇다면 이 웹은 어떻게 구성되어 있을까요?<br>먼저 frontend - backend로 나뉘는데요.<br>프론트엔드는 사용자경험을 위한 UI제공을 하고 백엔드는 서버나 디비를 다룹니다.<br>한마디로 프론트엔드는 사용자에게 보이는 부분을 다루고요!<br>백엔드는 보이지 않는 부분을 다루는 것이지요.<br>HTML은 이 프론트엔드에서 가장 중요한 웹사이트의 구조를 담고있습니다.<br>구조를 잘 쌓아야 튼튼한 프론트엔드영역이 완성되겠지요?</p>
<h1 id="HTML5란-무엇"><a href="#HTML5란-무엇" class="headerlink" title="HTML5란 무엇?"></a>HTML5란 무엇?</h1><p>HTML5는 이런 html에서 가장 최신 버전의 문법입니다.<br>성능이 많이 발전해서 javascript와 힘을 합하면 멋진 게임도 만들어 낼 수 있습니다.<br>그리고 무엇보다 눈에 띄는 점은 역시 의미론적으로 변신했다는 것인데요!<br>HTML5가 의미론적으로 변하면서 구글검색엔진이나 네이버검색엔진 등이 효율적으로 우리의 웹문서를 읽게 되면서 많은 이득을 가져올 수 있게 되었습니다.<br>한마디로 웹을 우리의 입맛에 더 잘 맞게 개발할 수 있게 되었습니다!</p>
<h1 id="어떻게-공부해야-빠르고-튼튼할까"><a href="#어떻게-공부해야-빠르고-튼튼할까" class="headerlink" title="어떻게 공부해야 빠르고 튼튼할까?"></a>어떻게 공부해야 빠르고 튼튼할까?</h1><p>우선 제가 가장 추천하는 방법은 생활코딩 강의를 듣는 것입니다.<br>opentutorials.org 이곳에서 HTML강좌를 무료로 진행합니다.<br>그리고는 w3schools.com 에서 튜토리얼을 한번 진행합니다.<br>그리고는 다음으로 css공부를 진행하는 것을 추천드립니다.<br>html로 구조를 짠 다음에는 css로 맛깔나게 꾸미는게 재밌거든요!<br>그럼 다음글로 css3의 추천 공부법을 알려드리도록 하겠습니다.</p>
]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;HTML이란-무엇&quot;&gt;&lt;a href=&quot;#HTML이란-무엇&quot; class=&quot;headerlink&quot; title=&quot;HTML이란 무엇?&quot;&gt;&lt;/a&gt;HTML이란 무엇?&lt;/h1&gt;&lt;p&gt;우선 html이야기를 하기 이전에 웹 이야기를 빼놓을 수가 없군요.&lt;br
    
    </summary>
    
      <category term="WEB" scheme="https://penglover.github.io/categories/WEB/"/>
    
      <category term="HTML/CSS" scheme="https://penglover.github.io/categories/WEB/HTML-CSS/"/>
    
    
      <category term="web" scheme="https://penglover.github.io/tags/web/"/>
    
      <category term="html" scheme="https://penglover.github.io/tags/html/"/>
    
  </entry>
  
  <entry>
    <title>하이브리드 웹앱은 왜 생겼을까?</title>
    <link href="https://penglover.github.io/2017/01/17/why-hybrid-app/"/>
    <id>https://penglover.github.io/2017/01/17/why-hybrid-app/</id>
    <published>2017-01-17T07:36:41.000Z</published>
    <updated>2017-01-17T08:02:19.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="하이브리드-웹앱의-탄생"><a href="#하이브리드-웹앱의-탄생" class="headerlink" title="하이브리드 웹앱의 탄생"></a>하이브리드 웹앱의 탄생</h1><p>하이브리드 웹앱을 이야기하려면 웹앱과 네이티브앱에 대한 이야기가 필요합니다.<br>웹앱은 브라우저를 바탕으로 어디에서나 활용할 수 있습니다.<br>(대부분의 플랫폼에 브라우저는 있으닌깐요! 맥북이든 윈도우든 스마트폰이든 기타등등이든..)<br>네이티브 앱은 그와 반대로 개발환경과 대상이 제한적이지만 스마트폰의 하드웨어 기능을 직접 사용할 수 있는 특혜가 있습니다.<br>기타 여러가지 차이점이 있는데 아래표로 말을 대신하겠습니다.<br><img src="https://penglover.github.io/images/webappvsnative.jpeg" alt="네이티브앱vs웹앱"></p>
<p>그렇다면 둘의 장점을 취합할수는 없을까요?<br>당연히 이런 시도가 있었고 그 끝에 나온것이 하이브리드 웹앱입니다.<br>하이브리드앱이란 웹표준 기술을 그대로 사용하여 웹앱을 개발한 후에 오픈 소스 크로스 프레임워크를 이용하여 네이티브앱으로 변환시켜 배포되는 앱 형식을 의미합니다.<br>(대표적인 크로스 프레임워크로 폰갭이 있습니다.)<br>그리고 또한 네이티브방식과 웹앱의 방식을 섞어서 개발할 수도 있게 되었습니다.<br>하이브리드웹앱이 네이티브앱과 웹앱의 경계를 허물어 준것이지요!</p>
]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;하이브리드-웹앱의-탄생&quot;&gt;&lt;a href=&quot;#하이브리드-웹앱의-탄생&quot; class=&quot;headerlink&quot; title=&quot;하이브리드 웹앱의 탄생&quot;&gt;&lt;/a&gt;하이브리드 웹앱의 탄생&lt;/h1&gt;&lt;p&gt;하이브리드 웹앱을 이야기하려면 웹앱과 네이티브앱에 대한
    
    </summary>
    
      <category term="WEB" scheme="https://penglover.github.io/categories/WEB/"/>
    
      <category term="HybridWebApp" scheme="https://penglover.github.io/categories/WEB/HybridWebApp/"/>
    
    
      <category term="web" scheme="https://penglover.github.io/tags/web/"/>
    
      <category term="app" scheme="https://penglover.github.io/tags/app/"/>
    
  </entry>
  
  <entry>
    <title>하이브리드웹앱 vs 네이티브앱 비교해보자</title>
    <link href="https://penglover.github.io/2017/01/17/hybid-vs-native-app/"/>
    <id>https://penglover.github.io/2017/01/17/hybid-vs-native-app/</id>
    <published>2017-01-17T06:51:59.000Z</published>
    <updated>2017-01-17T08:02:07.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="누가-더-빠를까"><a href="#누가-더-빠를까" class="headerlink" title="누가 더 빠를까?"></a>누가 더 빠를까?</h1><p>흔히들 네이티브앱의 가장 큰 강점으로 빠르기를 꼽습니다.<br>그런데 정말 빠를까요? 또 빠르면 얼만큼 빠를까요?<br>정확히 말씀드릴 수 있는부분은 결코 성능차이가 크지 않다는 것입니다.<br>물론 매우 무겁고 힘든 프로젝트들은 당연히 네이티브로 가야하는 것이 맞습니다.<br>그러나 평범한 프로젝트들은 하이브리드앱과 네이티브앱이 별 속도차이가 없습니다.<br>(개인적인 견해이긴 하지만 실제로 두 방법으로 모두 개발하는 개발사에서 이야기를 들었습니다.)<br>자바스크립트로 앱을 만들어주는 프레임워크인 fuse도 이미 네이티브를 따라잡았다고 광고를 하죠.<br>하이브리드 웹앱이 일반적으로 훨씬 개발속도가 빠른 만큼 자신의 프로젝트의 규모를 보고 잘 판단해서 결정해야 할 것 같습니다.<br>속도는 한마디로 ‘부분적으로 네이티브가 더 빠르다’라고 할 수 있겠습니다.</p>
<h1 id="핸드폰-자원을-얼마나-활용가능할까-API"><a href="#핸드폰-자원을-얼마나-활용가능할까-API" class="headerlink" title="핸드폰 자원을 얼마나 활용가능할까?(API)"></a>핸드폰 자원을 얼마나 활용가능할까?(API)</h1><p>흔히들 하이브리드 웹앱은 네이티브가 할 수 있는 수많은 일들을 아예 못한다고 생각합니다.<br>하지만 큰 오산입니다. 푸쉬알림 등등 거의 전부다 가능합니다!<br>물론 일부 문서화가 잘 안되어있어서 힘든 것들이 있지요.<br>심각한 커스터마이징이 필요하다면 네이티브가 옳은 선택일 것입니다.<br>하지만 일반적인 UI를 가지고 푸쉬알림 등의 기능만 필요하다면 하이브리드 웹앱이 더 좋은 판단이라고 생각됩니다.</p>
<h1 id="유지보수는-어느쪽이-더-쉬울까"><a href="#유지보수는-어느쪽이-더-쉬울까" class="headerlink" title="유지보수는 어느쪽이 더 쉬울까?"></a>유지보수는 어느쪽이 더 쉬울까?</h1><p>하이브리드 웹앱이 압도적으로 더 쉽습니다.<br>단순히 안드로이드와 IOS를 동시에 관리할 수 있기 때문이 아닙니다.<br>서버에서 관리할 수 있는 자원이 태생적으로 더 많을 수 밖에 없습니다.<br>따라서 유지보수 또한 하이브리드 웹앱이 일반적으로 수월합니다.</p>
<h1 id="개발기간-단가는-어떨까"><a href="#개발기간-단가는-어떨까" class="headerlink" title="개발기간 + 단가는 어떨까?"></a>개발기간 + 단가는 어떨까?</h1><p>개발기간은 네이티브앱이 압도적으로 길게 걸립니다.<br>단가 또한 마찬가지이지요.<br>저는 네이티브앱 개발이 3배힘들다고 생각합니다.<br>IOS와 안드로이드를 둘다 만들어줘야 할 뿐아니라 개발자 단가도 웹개발자에 비해 앱개발자가 더 비싼편입니다.</p>
<h1 id="결론"><a href="#결론" class="headerlink" title="결론"></a>결론</h1><p>커스터마이징이 심한 어플 + 매우 무거운 어플이라면 네이티브 앱을,<br>그런게 아니라면 하이브리드 웹앱을 추천합니다.<br>또한 서버에서 관리할 자원이 많아도 하이브리드 웹앱을 추천합니다.</p>
]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;누가-더-빠를까&quot;&gt;&lt;a href=&quot;#누가-더-빠를까&quot; class=&quot;headerlink&quot; title=&quot;누가 더 빠를까?&quot;&gt;&lt;/a&gt;누가 더 빠를까?&lt;/h1&gt;&lt;p&gt;흔히들 네이티브앱의 가장 큰 강점으로 빠르기를 꼽습니다.&lt;br&gt;그런데 정말 빠를
    
    </summary>
    
      <category term="WEB" scheme="https://penglover.github.io/categories/WEB/"/>
    
      <category term="HybridWebApp" scheme="https://penglover.github.io/categories/WEB/HybridWebApp/"/>
    
    
      <category term="web" scheme="https://penglover.github.io/tags/web/"/>
    
      <category term="app" scheme="https://penglover.github.io/tags/app/"/>
    
  </entry>
  
  <entry>
    <title>sigmoid함수가 버려진 이유 - ReLU</title>
    <link href="https://penglover.github.io/2017/01/15/relu-vs-sigmoid/"/>
    <id>https://penglover.github.io/2017/01/15/relu-vs-sigmoid/</id>
    <published>2017-01-15T12:53:25.000Z</published>
    <updated>2017-01-15T13:03:36.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="ReLU"><a href="#ReLU" class="headerlink" title="ReLU"></a>ReLU</h1><p>많은 분들이 아시듯이 머신러닝에서는 sigmoid함수를 써서 작업했었습니다.<br>그 이유는 아래의 글에서 이미 다루었습니다.<br><a href="https://penglover.github.io/2017/01/15/algorithm-sigmoid/">https://penglover.github.io/2017/01/15/algorithm-sigmoid/</a></p>
<p>그런데 이 sigmoid는 사실 전에 머신러닝 붐을 약화시킨 주범입니다.<br>바로 hidden layer 즉 층이 깊어지면 깊어질수록 정확성을 오히려 떨어뜨린다는 것입니다.<br>sigmoid 특성상 마이너스 값을 0에 가깝게 만듭니다.<br>따라서 관계가 깊어지면 깊어질수록 미분의 체인룰에 의해 sigmoid된 값들이 곱해질때<br>모두다 0에 가까운 값에 수렴하게 되어 input 값이 최종값에 아무런 영향을 끼치지 못하는 사태가 벌어지게 됩니다.<br>이를 위해 탄생한게 ReLU입니다.<br>매우 심플한데요.<br>0이하의 값이 들어오면 0을 출력하고 0이상의 값이 오면 비례함수로 그냥 내보내는 겁니다.<br><img src="https://upload.wikimedia.org/wikipedia/en/thumb/6/6c/Rectifier_and_softplus_functions.svg/440px-Rectifier_and_softplus_functions.svg.png" alt="ReLU"><br>감이 오시죠?<br>아! 물론 sigmoid는 여전히 마지막 layer에서 사용하고 있습니다.<br>마지막에는 0에서 1사이의 값으로 출력할 필요가 있거든요!<br>실제로 이 방법으로 hidden layer를 늘렸을때 즉 딥러닝에서 엄청난 결과를 가져옵니다.<br>감이 안오시는 분들은 아래의 김성훈 교수님의 강의를 들어보세요 ㅎㅎ<br><div class="video-container"><iframe src="//www.youtube.com/embed/cKtg_fpw88c" frameborder="0" allowfullscreen></iframe></div></p>
]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;ReLU&quot;&gt;&lt;a href=&quot;#ReLU&quot; class=&quot;headerlink&quot; title=&quot;ReLU&quot;&gt;&lt;/a&gt;ReLU&lt;/h1&gt;&lt;p&gt;많은 분들이 아시듯이 머신러닝에서는 sigmoid함수를 써서 작업했었습니다.&lt;br&gt;그 이유는 아래의 글에서 이미
    
    </summary>
    
      <category term="ML" scheme="https://penglover.github.io/categories/ML/"/>
    
      <category term="DeepLearning" scheme="https://penglover.github.io/categories/ML/DeepLearning/"/>
    
    
      <category term="machinelearning" scheme="https://penglover.github.io/tags/machinelearning/"/>
    
  </entry>
  
  <entry>
    <title>백프로퍼게이션(역전파)에 대한 친절한 강의</title>
    <link href="https://penglover.github.io/2017/01/15/backpropagation/"/>
    <id>https://penglover.github.io/2017/01/15/backpropagation/</id>
    <published>2017-01-15T11:32:11.000Z</published>
    <updated>2017-01-15T11:41:27.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="backpropagation"><a href="#backpropagation" class="headerlink" title="backpropagation"></a>backpropagation</h1><p>역전파 알고리즘, 즉 백프로퍼게이션 알고리즘은 머신러닝, 딥러닝의 핵심으로 많이 쓰입니다.<br>어떻게 뉴런들을 학습시킬 것이냐? 에 대한 해답을 던져준 것이기 때문이죠.<br>쉽게 말하면 feed forward를 통해 결과값을 우선 얻습니다.<br>그리곤 실제값과의 차이를 통해 backpropagation으로 값들을 update시키죠.<br>각 값들을 update시키는 기준은 무엇일까요?<br>바로 미분을 통해서입니다.<br>미분을 아는분들은 감이 오실겁니다.<br>미분은 해당 값에서의 변화량이지요.<br>쉽게 말해 전체 알고리즘을 f라고 두고 해당점을 a라고 둔다면?<br>f를 a에 대해 미분하면 순간변화량, 즉 a가 f에 미치는 영향을 알 수 있습니다.<br>이에 따라서 값을 매기가 update 자료로 삼지요.<br>아래는 김성훈 교수님의 아주 친절한 강의입니다.<br><div class="video-container"><iframe src="//www.youtube.com/embed/573EZkzfnZ0" frameborder="0" allowfullscreen></iframe></div></p>
<p>미분을 잘 모르는 분들을 위해서도 강의를 찍으셨습니다.<br><div class="video-container"><iframe src="//www.youtube.com/embed/oZyvmtqLmLo" frameborder="0" allowfullscreen></iframe></div></p>
]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;backpropagation&quot;&gt;&lt;a href=&quot;#backpropagation&quot; class=&quot;headerlink&quot; title=&quot;backpropagation&quot;&gt;&lt;/a&gt;backpropagation&lt;/h1&gt;&lt;p&gt;역전파 알고리즘, 즉 백프로퍼게이
    
    </summary>
    
      <category term="ML" scheme="https://penglover.github.io/categories/ML/"/>
    
      <category term="algorithm" scheme="https://penglover.github.io/categories/ML/algorithm/"/>
    
    
      <category term="machinelearning" scheme="https://penglover.github.io/tags/machinelearning/"/>
    
      <category term="algorithm" scheme="https://penglover.github.io/tags/algorithm/"/>
    
  </entry>
  
  <entry>
    <title>딥러닝이란 무엇일까? 김성훈 교수님의 말씀!</title>
    <link href="https://penglover.github.io/2017/01/15/what-is-deep-learning/"/>
    <id>https://penglover.github.io/2017/01/15/what-is-deep-learning/</id>
    <published>2017-01-15T10:09:31.000Z</published>
    <updated>2017-01-15T10:30:03.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="딥러닝이란"><a href="#딥러닝이란" class="headerlink" title="딥러닝이란?"></a>딥러닝이란?</h1><p>딥러닝이란 용어가 최근들어 많이 쓰이고 있습니다.<br>머신 러닝의 일종으로 간단한 learning 구조를 쌓아 올려가며 순차적으로 학습하는 계층적 구조의 학습법이라는 정의가 있기는 하지만 잘 와닿지가 않죠?<br>김성훈 교수님의 강의를 공유합니다.</p>
<p><strong>딥러닝이란(상)</strong><br><div class="video-container"><iframe src="//www.youtube.com/embed/n7DNueHGkqE" frameborder="0" allowfullscreen></iframe></div><br><strong>딥러닝이란(하)</strong><br><div class="video-container"><iframe src="//www.youtube.com/embed/AByVbUX1PUI" frameborder="0" allowfullscreen></iframe></div></p>
<p><a href="http://hunkim.github.io/ml/" rel="external nofollow noopener noreferrer" target="_blank">http://hunkim.github.io/ml/</a> 에 가면 더 많은 강의들이 있습니다.</p>
]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;딥러닝이란&quot;&gt;&lt;a href=&quot;#딥러닝이란&quot; class=&quot;headerlink&quot; title=&quot;딥러닝이란?&quot;&gt;&lt;/a&gt;딥러닝이란?&lt;/h1&gt;&lt;p&gt;딥러닝이란 용어가 최근들어 많이 쓰이고 있습니다.&lt;br&gt;머신 러닝의 일종으로 간단한 learning 
    
    </summary>
    
      <category term="ML" scheme="https://penglover.github.io/categories/ML/"/>
    
      <category term="DeepLearning" scheme="https://penglover.github.io/categories/ML/DeepLearning/"/>
    
    
      <category term="machinelearning" scheme="https://penglover.github.io/tags/machinelearning/"/>
    
  </entry>
  
  <entry>
    <title>머신러닝 코드 최적화하기 by rate, overfitting, regularization</title>
    <link href="https://penglover.github.io/2017/01/15/how-can-upgrade-mlcode/"/>
    <id>https://penglover.github.io/2017/01/15/how-can-upgrade-mlcode/</id>
    <published>2017-01-15T08:07:38.000Z</published>
    <updated>2017-01-15T10:11:44.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="머신러닝-코드-최적화하기"><a href="#머신러닝-코드-최적화하기" class="headerlink" title="머신러닝 코드 최적화하기"></a>머신러닝 코드 최적화하기</h1><p><strong>rate</strong><br>항상 우리는 머신러닝 코드를 짤때 learning rate라는 값을 줍니다.<br>gradient descent알고리즘을 쓸 때에 업데이트 정도를 조절해주는데요.<br>우리는 이 learning rate 를 조절함으로써 코드를 최적화 할 수 있습니다.<br>너무 작은값을 주면 어떻게 될까요?<br>또는 너무 큰값을 주면 어떻게 될까요?<br><img src="https://penglover.github.io/images/learningrate.png" alt="compare_learningrate"><br>위의 그림처럼 되어서 최적화가 안됩니다.<br>해결방안은?<br>print로 꾸준히 cost함수의 변화를 체크하는 것이 최선입니다.</p>
<p><strong>overfitting</strong><br>overfitting이라 하면 주로 test data가 적어서 일어납니다.<br>무리하게 적은 데이터로 fitting을 하려다보니 이상해 지는 것이지요.<br>또는 weight간의 값이 편차가 심하거나 해도 마찬가지로 일어납니다.<br>그래프가 구부러져 보인다고 해서 ‘구부러졌다’라고 표현하기도 합니다.<br>표준정규분포를 혹시 아시나요?<br>z = (x-평균)/표준편차<br>고등학교 수학시간에 한번 보셨을 겁니다.<br>이것을 이용해서 weight간의 격차를 일반화해줌으로서 해결하는 경우가 대부분입니다.<br>또는 regularization을 통해 해결할 수 있는데요.</p>
<p><strong>regularization</strong><br>기존의 우리가 cost를 구하는 개념에서 weight의 제곱을 또 추가한것을 구하는 개념입니다.<br>gradient descent 알고리즘을 사용한다면 자동으로 weight의 제곱까지 고려해서 minimize를 시킬 것이고 그에따라서 자동으로 weight의 값들도 하향 평준화 시켜서 값을 낮춤으로써 구부러짐을 방지해주지요.<br>구부러짐이 뭐지 하는생각이 들 수 있습니다.<br><img src="https://penglover.github.io/images/regularization.png" alt="regularization"><br><img src="http://cs231n.github.io/assets/nn1/reg_strengths.jpeg" alt="overfitting_example"></p>
<p>위에서 보이듯 람다값이 작을수록 weight 값을 신경쓰지 않겠다는 것입니다.</p>
]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;머신러닝-코드-최적화하기&quot;&gt;&lt;a href=&quot;#머신러닝-코드-최적화하기&quot; class=&quot;headerlink&quot; title=&quot;머신러닝 코드 최적화하기&quot;&gt;&lt;/a&gt;머신러닝 코드 최적화하기&lt;/h1&gt;&lt;p&gt;&lt;strong&gt;rate&lt;/strong&gt;&lt;br&gt;항
    
    </summary>
    
      <category term="ML" scheme="https://penglover.github.io/categories/ML/"/>
    
      <category term="algorithm" scheme="https://penglover.github.io/categories/ML/algorithm/"/>
    
    
      <category term="machinelearning" scheme="https://penglover.github.io/tags/machinelearning/"/>
    
      <category term="algorithm" scheme="https://penglover.github.io/tags/algorithm/"/>
    
  </entry>
  
  <entry>
    <title>텐서플로우에서 softmax 메서드를 사용해 봅시다!</title>
    <link href="https://penglover.github.io/2017/01/15/tensorflow-softmaxC/"/>
    <id>https://penglover.github.io/2017/01/15/tensorflow-softmaxC/</id>
    <published>2017-01-15T06:07:59.000Z</published>
    <updated>2017-01-15T07:17:07.000Z</updated>
    
    <content type="html"><![CDATA[<p>우선 softmax란?<br>logistic을 지난번 포스팅에서 다뤘죠?<br>(<a href="https://penglover.github.io/2017/01/15/tensorflow-logisticC/">https://penglover.github.io/2017/01/15/tensorflow-logisticC/</a>)<br>그것을 일반화 한것이라고 보면 됩니다.<br>logistic은 계산을 해서 1, 0만 나누었다면<br>softmax는 같은 계산을 해서 각 class별로 확률을 매기죠.<br>가장 높은 확률의 편을 들어주는 것입니다.</p>
<p>텐서플로우가 아니라면 softmax 부분을 어떻게 구현해야 할까요?<br>일일히 class별로 weight와 bias를 계산해서 sigmoid 씌우고 주저리주저리…<br>어휴 참 끔찍합니다.<br>다행히 tensorflow에서는 메서드로 이를 제공하는데요.<br>아래의 코드는 weight와 bias를 행렬로 처리해서 W로 묶어서 두었습니다.<br>hypothesis, 즉 기대값은 X와 W의 행렬곱을 softmax처리 한 것입니다.<br>cost함수는 오류를 극대화 하기 위해서 + 선형성을 위해서 저렇게 한 것이라고 생각하면 됩니다.</p>
<p>softmax에 대해서 아는 분이라면 다음의 코드가 쉽게 이해가 가실겁니다.<br><figure class="highlight plain"><figcaption><span>input.txt</span></figcaption><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line">#x0 x1 x2 y[A   B   C]</div><div class="line">1   2   1   0   0   1</div><div class="line">1   3   2   0   0   1</div><div class="line">1   3   4   0   0   1</div><div class="line">1   5   5   0   1   0</div><div class="line">1   7   5   0   1   0</div><div class="line">1   2   5   0   1   0</div><div class="line">1   6   6   1   0   0</div><div class="line">1   7   7   1   0   0</div></pre></td></tr></table></figure><br>아래는 예제 코드입니다.<br><figure class="highlight plain"><figcaption><span>softmax.py</span></figcaption><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div></pre></td><td class="code"><pre><div class="line">import tensorflow as tf</div><div class="line">import numpy as np</div><div class="line"></div><div class="line">xy = np.loadtxt(&apos;input.txt&apos;, unpack=True, dtype=&apos;float32&apos;)</div><div class="line"></div><div class="line">x_data = np.transpose(xy[0:3])</div><div class="line">y_data = np.transpose(xy[3:])</div><div class="line"></div><div class="line">X = tf.placeholder(&quot;float&quot;, [None, 3])</div><div class="line">Y = tf.placeholder(&quot;float&quot;, [None, 3])</div><div class="line"></div><div class="line">W = tf.Variable(tf.zeros([3, 3]))</div><div class="line"></div><div class="line">hypothesis = tf.nn.softmax(tf.matmul(X, W))</div><div class="line"></div><div class="line">learning_rate = 0.01</div><div class="line"></div><div class="line">cost = tf.reduce_mean(-tf.reduce_sum(Y * tf.log(hypothesis), reduction_indices=1))</div><div class="line"></div><div class="line">optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(cost)</div><div class="line"></div><div class="line"></div><div class="line">init = tf.global_variables_initializer()</div><div class="line"></div><div class="line">sess = tf.Session()</div><div class="line"></div><div class="line">sess.run(init)</div><div class="line"></div><div class="line">for step in range(2001):</div><div class="line">    sess.run(optimizer, feed_dict=&#123;X: x_data, Y: y_data&#125;)</div><div class="line">    if step % 200 == 0:</div><div class="line">         print (step, sess.run(cost, feed_dict=&#123;X: x_data, Y: y_data&#125;), sess.run(W))</div><div class="line"></div><div class="line">a = sess.run(hypothesis, feed_dict=&#123;X: [[1, 11, 7]]&#125;)</div><div class="line">print (&quot;a :&quot;, a, sess.run(tf.arg_max(a, 1)))</div><div class="line"></div><div class="line">b = sess.run(hypothesis, feed_dict=&#123;X: [[1, 3, 4]]&#125;)</div><div class="line">print (&quot;b :&quot;, b, sess.run(tf.arg_max(b, 1)))</div><div class="line"></div><div class="line">c = sess.run(hypothesis, feed_dict=&#123;X: [[1, 1, 0]]&#125;)</div><div class="line">print (&quot;c :&quot;, c, sess.run(tf.arg_max(c, 1)))</div></pre></td></tr></table></figure><br><strong>결과값</strong><br>0 1.09048 [[-0.00083333  0.00041667  0.00041667]<br> [ 0.00166667  0.00291667 -0.00458333]<br> [ 0.00166667  0.00416667 -0.00583333]]<br>200 0.985653 [[-0.21679303 -0.05050437  0.26729742]<br> [ 0.02901031 -0.06265054  0.03364029]<br> [ 0.04244109  0.12451769 -0.16695869]]<br>400 0.926073 [[-0.41495511 -0.10318027  0.51813519]<br> [ 0.03762176 -0.10302337  0.06540174]<br> [ 0.07457665  0.17761268 -0.25218898]]<br>600 0.879342 [[-0.59596533 -0.1515553   0.74752003]<br> [ 0.04480708 -0.11983915  0.07503238]<br> [ 0.10447746  0.20644082 -0.31091776]]<br>800 0.840971 [[-0.76270223 -0.19499816  0.95770001]<br> [ 0.05223157 -0.12450957  0.07227841]<br> [ 0.13095778  0.22218271 -0.35314   ]]<br>1000 0.808647 [[-0.91752577 -0.2334879   1.15101326]<br> [ 0.06007884 -0.12292791  0.06284945]<br> [ 0.15438823  0.23068959 -0.38507724]]<br>1200 0.780959 [[-1.06231129 -0.26727253  1.32958329]<br> [ 0.06808005 -0.11823834  0.05015875]<br> [ 0.17550454  0.23514733 -0.41065112]]<br>1400 0.756943 [[-1.19854808 -0.29670808  1.49525583]<br> [ 0.07591439 -0.11214777  0.03623381]<br> [ 0.19498996  0.237331   -0.43232018]]<br>1600 0.735892 [[-1.32743537 -0.32218221  1.64961684]<br> [ 0.08333746 -0.10557999  0.022243  ]<br> [ 0.21336642  0.23823628 -0.45160189]]<br>1800 0.717269 [[-1.44994974 -0.34407791  1.79402602]<br> [ 0.09020081 -0.09902246  0.00882213]<br> [ 0.23099625  0.23841871 -0.46941414]]<br>2000 0.700649 [[-1.56689739 -0.36275655  1.92965221]<br> [ 0.09643649 -0.09271803 -0.00371792]<br> [ 0.24811605  0.23818412 -0.48629922]]<br>a : [[ 0.68849677  0.26731515  0.04418808]] [0]<br>b : [[ 0.24322268  0.44183081  0.3149465 ]] [1]<br>c : [[ 0.02974809  0.08208466  0.8881672 ]] [2]</p>
<p>정말 놀랍죠?<br>참고로 transpose는 열과 행을 바꾸는 것입니다.<br>reduction_indices=1 이부분도 뭔지 모르실수가 있는데 아래의 링크에 설명했습니다.<br><a href="https://penglover.github.io/2017/01/15/tensorflow-reduction-indices/">https://penglover.github.io/2017/01/15/tensorflow-reduction-indices/</a></p>
<p>softmax가 이해가 안가시는분들은 이걸봐주세요.<br>김성훈님의 강의입니다.<br><div class="video-container"><iframe src="//www.youtube.com/embed/MFAnsx1y9ZI" frameborder="0" allowfullscreen></iframe></div><br>cost가 이해가 안가시는 분들은 이걸봐주세요.<br>마찬가지로 김성훈 교수님의 강의입니다.<br><div class="video-container"><iframe src="//www.youtube.com/embed/jMU9G5WEtBc" frameborder="0" allowfullscreen></iframe></div></p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;우선 softmax란?&lt;br&gt;logistic을 지난번 포스팅에서 다뤘죠?&lt;br&gt;(&lt;a href=&quot;https://penglover.github.io/2017/01/15/tensorflow-logisticC/&quot;&gt;https://penglover.git
    
    </summary>
    
      <category term="ML" scheme="https://penglover.github.io/categories/ML/"/>
    
      <category term="TensorFlow" scheme="https://penglover.github.io/categories/ML/TensorFlow/"/>
    
    
      <category term="machinelearning" scheme="https://penglover.github.io/tags/machinelearning/"/>
    
      <category term="tensorflow" scheme="https://penglover.github.io/tags/tensorflow/"/>
    
  </entry>
  
  <entry>
    <title>텐서플로우에서 reduction_indices 속성은 무엇일까?</title>
    <link href="https://penglover.github.io/2017/01/15/tensorflow-reduction-indices/"/>
    <id>https://penglover.github.io/2017/01/15/tensorflow-reduction-indices/</id>
    <published>2017-01-15T05:29:16.000Z</published>
    <updated>2017-01-15T05:33:48.000Z</updated>
    
    <content type="html"><![CDATA[<p>텐서플로우를 공부하다보면 reduction_indices 속성이 등장합니다.<br>reduce_mean이라든가 연산메서드에서 등장하는 속성인데요.<br><figure class="highlight plain"><figcaption><span>simple.txt</span></figcaption><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">&apos;x&apos; is [[1., 1.]</div><div class="line">        [2., 2.]]</div></pre></td></tr></table></figure><br>다음의 행렬이 있다고 해보겠습니다.<br>결과값은 어떻게 될까요?<br>tf.reduce_mean(x) ==&gt; 1.5<br>tf.reduce_mean(x, 0) ==&gt; [1.5, 1.5]<br>tf.reduce_mean(x, 1) ==&gt; [1.,  2.]</p>
<p>자 아시겠죠?<br>아무 값도 주지 않으면 전부다 처리해버립니다.<br>0으로 하면 열끼리 처리하고 1로 하면 행끼리 처리합니다.<br>도움이 되셨길 바라며 포스팅 마무리하겠습니다~</p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;텐서플로우를 공부하다보면 reduction_indices 속성이 등장합니다.&lt;br&gt;reduce_mean이라든가 연산메서드에서 등장하는 속성인데요.&lt;br&gt;&lt;figure class=&quot;highlight plain&quot;&gt;&lt;figcaption&gt;&lt;span&gt;si
    
    </summary>
    
      <category term="ML" scheme="https://penglover.github.io/categories/ML/"/>
    
      <category term="TensorFlow" scheme="https://penglover.github.io/categories/ML/TensorFlow/"/>
    
    
      <category term="machinelearning" scheme="https://penglover.github.io/tags/machinelearning/"/>
    
      <category term="tensorflow" scheme="https://penglover.github.io/tags/tensorflow/"/>
    
  </entry>
  
  <entry>
    <title>텐서플로우로 logistic classification 구현해보자</title>
    <link href="https://penglover.github.io/2017/01/15/tensorflow-logisticC/"/>
    <id>https://penglover.github.io/2017/01/15/tensorflow-logisticC/</id>
    <published>2017-01-15T04:19:22.000Z</published>
    <updated>2017-01-15T05:30:03.000Z</updated>
    
    <content type="html"><![CDATA[<p>logistic classification은 다들알고 계시죠?<br>true인지 false인지를 판가름해봅시다.<br>실제로 양자택일의 상황이 올 경우가 굉장히 많지요.<br>자, 코드부터 보겠습니다.<br>input.txt는 다음과 같습니다.<br><figure class="highlight plain"><figcaption><span>input.txt</span></figcaption><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line">#x0 x1 x2 y</div><div class="line">1   2   1   0</div><div class="line">1   3   2   0</div><div class="line">1   3   5   0</div><div class="line">1   5   5   1</div><div class="line">1   7   5   1</div><div class="line">1   2   5   1</div></pre></td></tr></table></figure><br>코드부분 입니다.<br><figure class="highlight plain"><figcaption><span>logisticC.py</span></figcaption><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div></pre></td><td class="code"><pre><div class="line">import tensorflow as tf</div><div class="line">import numpy as np</div><div class="line"></div><div class="line">xy = np.loadtxt(&apos;input.txt&apos;, unpack=True, dtype=&apos;float32&apos;)</div><div class="line">x_data = xy[0:-1]</div><div class="line">y_data = xy[-1]</div><div class="line"></div><div class="line">X = tf.placeholder(tf.float32)</div><div class="line">Y = tf.placeholder(tf.float32)</div><div class="line"></div><div class="line">W = tf.Variable(tf.random_uniform([1, len(x_data)], -1.0, 1.0))</div><div class="line"></div><div class="line">h = tf.matmul(W, X)</div><div class="line">hypothesis = tf.div(1., 1. + tf.exp(-h))</div><div class="line"></div><div class="line">cost = -tf.reduce_mean(Y * tf.log(hypothesis) + (1 - Y) * tf.log(1 - hypothesis))</div><div class="line"></div><div class="line">a = tf.Variable(0.1)  # learning rate, alpha</div><div class="line">optimizer = tf.train.GradientDescentOptimizer(a)</div><div class="line">train = optimizer.minimize(cost)  # goal is minimize cost</div><div class="line"></div><div class="line">init = tf.global_variables_initializer()</div><div class="line"></div><div class="line">sess = tf.Session()</div><div class="line">sess.run(init)</div><div class="line"></div><div class="line">for step in range(2001):</div><div class="line">    sess.run(train, feed_dict=&#123;X: x_data, Y: y_data&#125;)</div><div class="line">    if step % 200 == 0:</div><div class="line">        print (step, sess.run(cost, feed_dict=&#123;X: x_data, Y: y_data&#125;), sess.run(W))</div><div class="line"></div><div class="line">print (&apos;-----------------------------------------&apos;)</div><div class="line">print (sess.run(hypothesis, feed_dict=&#123;X: [[1], [2], [2]]&#125;) &gt; 0.5)</div><div class="line">print (sess.run(hypothesis, feed_dict=&#123;X: [[1], [5], [5]]&#125;) &gt; 0.5)</div><div class="line">print (sess.run(hypothesis, feed_dict=&#123;X: [[1, 1], [4, 0], [2, 10]]&#125;) &gt; 0.5)</div></pre></td></tr></table></figure></p>
<p><strong>결과값</strong><br>0 0.919001 [[ 0.8754766  -0.10433824  0.33632374]]<br>200 0.509501 [[-1.38300133  0.11766662  0.33868256]]<br>400 0.42692 [[-2.6384747   0.24237575  0.51069313]]<br>600 0.391719 [[-3.46154785  0.31578434  0.6304763 ]]<br>800 0.373097 [[-4.06127024  0.36348528  0.72200185]]<br>1000 0.361825 [[-4.52822399  0.39683989  0.79584837]]<br>1200 0.354366 [[-4.90821457  0.42141104  0.85761738]]<br>1400 0.34911 [[-5.22723818  0.44022152  0.91062367]]<br>1600 0.345229 [[-5.5013628   0.45505521  0.95699048]]<br>1800 0.342259 [[-5.74115181  0.46703169  0.99815571]]</p>
<h2 id="2000-0-339921-5-95390177-0-47688928-1-03513932"><a href="#2000-0-339921-5-95390177-0-47688928-1-03513932" class="headerlink" title="2000 0.339921 [[-5.95390177  0.47688928  1.03513932]]"></a>2000 0.339921 [[-5.95390177  0.47688928  1.03513932]]</h2><p>[[False]]<br>[[ True]]<br>[[False  True]]</p>
<p>주목해야할 부분은 cost함수 입니다.<br>왜 시그모이드 함수를 씌우고 log를 취했을까요?<br>0, 1의 값만을 갖는 true or false의 문제이기 때문인데요.<br>기존의 LinearRegression을 그대로 적용하면 최적화에 어려움이 있습니다.<br>어떤 어려움인지는 맨 아래 링크에 나와있구요.<br>그래서 sigmoid를 씌운 것입니다.</p>
<p>log를 취한 이유는 gradient descent 알고리즘의 최적화와 연관이 있는데요.<br>그냥 sigmoid 만 취하면 함수가 울퉁불퉁해져서 최적화가 힘듭니다.<br>때문에 log를 취해서 적용시키려고 하는 것이지요.<br>cost에 대해 모르시겠는 분들은 다음 동영상으로 학습해주세요.<br>김성훈 교수님의 강의입니다.<br><div class="video-container"><iframe src="//www.youtube.com/embed/6vzchGYEJBc" frameborder="0" allowfullscreen></iframe></div></p>
<p>기존의 LinearRegression 함수에 시그모이드 함수를 취했다는 것 이외에는 별 다른게 없죠?<br>하지만 sigmoid 함수의 필요성과 cost함수의 변화를 이해했다면 큰 발전입니다.<br>시그모이드 함수를 왜 취했는가를 모르신다면 아래의 url로 이동해주세요.<br><a href="https://penglover.github.io/2017/01/15/algorithm-sigmoid/">https://penglover.github.io/2017/01/15/algorithm-sigmoid/</a></p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;logistic classification은 다들알고 계시죠?&lt;br&gt;true인지 false인지를 판가름해봅시다.&lt;br&gt;실제로 양자택일의 상황이 올 경우가 굉장히 많지요.&lt;br&gt;자, 코드부터 보겠습니다.&lt;br&gt;input.txt는 다음과 같습니다.&lt;
    
    </summary>
    
      <category term="ML" scheme="https://penglover.github.io/categories/ML/"/>
    
      <category term="TensorFlow" scheme="https://penglover.github.io/categories/ML/TensorFlow/"/>
    
    
      <category term="machinelearning" scheme="https://penglover.github.io/tags/machinelearning/"/>
    
      <category term="tensorflow" scheme="https://penglover.github.io/tags/tensorflow/"/>
    
  </entry>
  
  <entry>
    <title>머신러닝에서는 왜 시그모이드함수를 쓰는지 알아보자</title>
    <link href="https://penglover.github.io/2017/01/15/algorithm-sigmoid/"/>
    <id>https://penglover.github.io/2017/01/15/algorithm-sigmoid/</id>
    <published>2017-01-15T03:27:36.000Z</published>
    <updated>2017-01-15T08:48:31.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="why-sigmoid"><a href="#why-sigmoid" class="headerlink" title="why sigmoid"></a>why sigmoid</h1><p>머신러닝 알고리즘을 공부하다가보면 시그모이드 함수를 마주쳤을 것입니다.<br>그런데 이게 진짜 과연 써야하는 것인가?<br>그냥 linear한 함수를 쓰면 안되나?<br>이런 의문을 바로 해결해준 유투브 강의가 있어서 소개합니다.<br>김성훈님의 강의입니다.<br><div class="video-container"><iframe src="//www.youtube.com/embed/PIjno6paszY" frameborder="0" allowfullscreen></iframe></div></p>
<p>Logistic classification을 설명해 주시면서 등장합니다.<br>이런 이유라면 충분히 시그모이드 함수의 등장이 이해가 가네요!</p>
]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;why-sigmoid&quot;&gt;&lt;a href=&quot;#why-sigmoid&quot; class=&quot;headerlink&quot; title=&quot;why sigmoid&quot;&gt;&lt;/a&gt;why sigmoid&lt;/h1&gt;&lt;p&gt;머신러닝 알고리즘을 공부하다가보면 시그모이드 함수를 마주쳤을 
    
    </summary>
    
      <category term="ML" scheme="https://penglover.github.io/categories/ML/"/>
    
      <category term="algorithm" scheme="https://penglover.github.io/categories/ML/algorithm/"/>
    
    
      <category term="machinelearning" scheme="https://penglover.github.io/tags/machinelearning/"/>
    
      <category term="algorithm" scheme="https://penglover.github.io/tags/algorithm/"/>
    
  </entry>
  
  <entry>
    <title>텐서플로우할 때 txt파일을 쉽게 배열로 가져오는법(numpy)</title>
    <link href="https://penglover.github.io/2017/01/15/tensorflow-numpy/"/>
    <id>https://penglover.github.io/2017/01/15/tensorflow-numpy/</id>
    <published>2017-01-15T02:50:55.000Z</published>
    <updated>2017-01-15T04:01:23.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="numpy"><a href="#numpy" class="headerlink" title="numpy"></a>numpy</h1><p>파이썬에 기본 내장된 라이브러리로 따로 설치할 필요가 없습니다.<br>텐서플로우를 활용하다가 손쉽게 txt파일을 배열로 바꾸기 위해 찾은 라이브러리입니다.<br>예를들어 다음의 텐서플로우 코드를 보겠습니다.<br><figure class="highlight plain"><figcaption><span>multiple_variables.py</span></figcaption><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div></pre></td><td class="code"><pre><div class="line">import tensorflow as tf</div><div class="line">import numpy as np</div><div class="line"></div><div class="line">xy = np.loadtxt(&apos;input.txt&apos;, unpack=True, dtype=&apos;float32&apos;)</div><div class="line">x_data = xy[0:-1]</div><div class="line">y_data = xy[-1]</div><div class="line"></div><div class="line">W = tf.Variable(tf.random_uniform([1, len(x_data)], -1, 1))</div><div class="line">b = tf.Variable(tf.random_uniform([1], -1, 1))</div><div class="line"></div><div class="line">hypothesis = tf.matmul(W, x_data)</div><div class="line"></div><div class="line">cost = tf.reduce_mean(tf.square(hypothesis - y_data))</div><div class="line"></div><div class="line">a = tf.Variable(0.1)  # learning rate, alpha</div><div class="line">optimizer = tf.train.GradientDescentOptimizer(a)</div><div class="line">train = optimizer.minimize(cost)  # goal is minimize cost</div><div class="line"></div><div class="line">init = tf.global_variables_initializer()</div><div class="line"></div><div class="line">sess = tf.Session()</div><div class="line">sess.run(init)</div><div class="line">print(x_data)</div><div class="line">for step in range(2001):</div><div class="line">    sess.run(train)</div><div class="line">    if step % 200 == 0:</div><div class="line">        print (step, sess.run(cost), sess.run(W))</div><div class="line"></div></pre></td></tr></table></figure></p>
<p>input.txt는 다음과 같습니다.<br><figure class="highlight plain"><figcaption><span>input.txt</span></figcaption><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">#x0 x1 x2 y</div><div class="line">1   1   0   1</div><div class="line">1   0   2   2</div><div class="line">1   3   0   3</div><div class="line">1   0   4   4</div><div class="line">1   5   0   5</div></pre></td></tr></table></figure><br>numpy를 임포트 한 뒤에 loadtxt로 손쉽게 txt파일을 가져 올 수 있습니다.<br><figure class="highlight plain"><figcaption><span>numpy.py</span></figcaption><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">xy = np.loadtxt(&apos;input.txt&apos;, unpack=True, dtype=&apos;float32&apos;)</div></pre></td></tr></table></figure><br>그리고 다음과 같이 활용이 가능하지요.<br><figure class="highlight plain"><figcaption><span>numpy.py</span></figcaption><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">x_data = xy[0:-1]</div><div class="line">y_data = xy[-1]</div></pre></td></tr></table></figure></p>
<p>x_data는 그럼 다음과 같은 값으로 나오게 됩니다.<br>[[ 1.  1.  1.  1.  1.]<br> [ 1.  0.  3.  0.  5.]<br> [ 0.  2.  0.  4.  0.]]<br> 참 쉽죠?<br> 행과 열을 바꾸고 싶다면 transpose를 이용하면 쉽게 바꿀 수 있어요.<br> 자 그럼 이제부터 txt파일을 손쉽게 배열로 바꿔서 tensorflow에 적용할 수 있으실 것입니다.</p>
<p> 위의 코드 자체가 궁금하시다면<br> <a href="https://penglover.github.io/2017/01/15/how-to-handle-multiple-variables-in-tensorflow/">https://penglover.github.io/2017/01/15/how-to-handle-multiple-variables-in-tensorflow/</a><br> 이 포스팅을 봐주세요!</p>
]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;numpy&quot;&gt;&lt;a href=&quot;#numpy&quot; class=&quot;headerlink&quot; title=&quot;numpy&quot;&gt;&lt;/a&gt;numpy&lt;/h1&gt;&lt;p&gt;파이썬에 기본 내장된 라이브러리로 따로 설치할 필요가 없습니다.&lt;br&gt;텐서플로우를 활용하다가 손쉽게 tx
    
    </summary>
    
      <category term="ML" scheme="https://penglover.github.io/categories/ML/"/>
    
      <category term="TensorFlow" scheme="https://penglover.github.io/categories/ML/TensorFlow/"/>
    
    
      <category term="machinelearning" scheme="https://penglover.github.io/tags/machinelearning/"/>
    
      <category term="tensorflow" scheme="https://penglover.github.io/tags/tensorflow/"/>
    
  </entry>
  
  <entry>
    <title>텐서플로우 LinearRegression 변수가 여러가지인경우 대처법</title>
    <link href="https://penglover.github.io/2017/01/15/how-to-handle-multiple-variables-in-tensorflow/"/>
    <id>https://penglover.github.io/2017/01/15/how-to-handle-multiple-variables-in-tensorflow/</id>
    <published>2017-01-15T02:28:27.000Z</published>
    <updated>2017-01-15T04:01:19.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="텐서플로우에서-선형회귀함수-적용중-변수가-여러개라면"><a href="#텐서플로우에서-선형회귀함수-적용중-변수가-여러개라면" class="headerlink" title="텐서플로우에서 선형회귀함수 적용중 변수가 여러개라면?"></a>텐서플로우에서 선형회귀함수 적용중 변수가 여러개라면?</h1><p>보통 우리는 hypothesis = a <em> w </em> x + b<br>이 모델을 기본으로 삼았습니다.<br>x가 input이고 hypothesis는 기대값이죠.<br>a는 learning rate이고 w는 weight b는 bias 입니다.</p>
<p>그런데 사실 어떤 요인에게 영향을 주는 요소가 한개일 경우가 잘 없죠?<br>두개 이상인 경우에는 어떻게 모델링을 할까요?<br>아주 간단하게 이런 경우를 모델링 할 수 있습니다.<br>hypothesis = a<em> (w1</em>x1 + w2*x2) + b<br>위 처럼 적용하면 되는데요. 코드를 살피겠습니다.<br>코드는 위의 hypothesis를 배열 형태로 구현하였습니다.<br>input 데이터는<br><figure class="highlight plain"><figcaption><span>input.txt</span></figcaption><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">#x0 x1 x2 y</div><div class="line">1   1   0   1</div><div class="line">1   0   2   2</div><div class="line">1   3   0   3</div><div class="line">1   0   4   4</div><div class="line">1   5   0   5</div></pre></td></tr></table></figure></p>
<figure class="highlight plain"><figcaption><span>multiple_variables.py</span></figcaption><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div></pre></td><td class="code"><pre><div class="line">import tensorflow as tf</div><div class="line">import numpy as np</div><div class="line"></div><div class="line">xy = np.loadtxt(&apos;input.txt&apos;, unpack=True, dtype=&apos;float32&apos;)</div><div class="line">x_data = xy[0:-1]</div><div class="line">y_data = xy[-1]</div><div class="line"></div><div class="line">W = tf.Variable(tf.random_uniform([1, len(x_data)], -1, 1))</div><div class="line">b = tf.Variable(tf.random_uniform([1], -1, 1))</div><div class="line"></div><div class="line">hypothesis = tf.matmul(W, x_data)</div><div class="line"></div><div class="line">cost = tf.reduce_mean(tf.square(hypothesis - y_data))</div><div class="line"></div><div class="line">a = tf.Variable(0.1)  # learning rate, alpha</div><div class="line">optimizer = tf.train.GradientDescentOptimizer(a)</div><div class="line">train = optimizer.minimize(cost)  # goal is minimize cost</div><div class="line"></div><div class="line">init = tf.global_variables_initializer()</div><div class="line"></div><div class="line">sess = tf.Session()</div><div class="line">sess.run(init)</div><div class="line">print(x_data)</div><div class="line">for step in range(2001):</div><div class="line">    sess.run(train)</div><div class="line">    if step % 200 == 0:</div><div class="line">        print (step, sess.run(cost), sess.run(W))</div><div class="line"></div></pre></td></tr></table></figure>
<p><strong>결과값</strong><br>[[ 1.  1.  1.  1.  1.]<br> [ 1.  0.  3.  0.  5.]<br> [ 0.  2.  0.  4.  0.]]<br>0 0.43461 [[-0.20677651  1.29921687  1.09060895]]<br>200 5.33032e-08 [[ -5.47317148e-04   1.00014389e+00   1.00017071e+00]]<br>400 2.52953e-13 [[ -1.20747086e-06   1.00000036e+00   1.00000048e+00]]<br>600 1.77636e-14 [[ -2.96712130e-07   1.00000012e+00   1.00000012e+00]]<br>800 1.77636e-14 [[ -2.96712130e-07   1.00000012e+00   1.00000012e+00]]<br>1000 1.77636e-14 [[ -2.96712130e-07   1.00000012e+00   1.00000012e+00]]<br>1200 1.77636e-14 [[ -2.96712130e-07   1.00000012e+00   1.00000012e+00]]<br>1400 1.77636e-14 [[ -2.96712130e-07   1.00000012e+00   1.00000012e+00]]<br>1600 1.77636e-14 [[ -2.96712130e-07   1.00000012e+00   1.00000012e+00]]<br>1800 1.77636e-14 [[ -2.96712130e-07   1.00000012e+00   1.00000012e+00]]<br>2000 1.77636e-14 [[ -2.96712130e-07   1.00000012e+00   1.00000012e+00]]</p>
<p>간단하죠?<br>배열값은 순서대로 b, w1, w2입니다.<br>cost도 1.77636e-14로 거의 0에 가깝게 되었네요.<br>print(x_data)는 numpy 라이브러리가 어떤식으로 데이터를 가져와 주는지 알려주기 위해 넣어봤어요.<br>#부분은 무시를 한 채로 아래의 데이터를 행렬 형식으로 가져와줍니다.<br>numpy가 더 궁금하다면 다음 포스트를 봐주세요.</p>
<p>아주 쉽게 우리는 배열을 이용해서 weight를 추가시켰습니다.<br>질문이 있으면 댓글로 달아주세요!</p>
]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;텐서플로우에서-선형회귀함수-적용중-변수가-여러개라면&quot;&gt;&lt;a href=&quot;#텐서플로우에서-선형회귀함수-적용중-변수가-여러개라면&quot; class=&quot;headerlink&quot; title=&quot;텐서플로우에서 선형회귀함수 적용중 변수가 여러개라면?&quot;&gt;&lt;/a&gt;텐
    
    </summary>
    
      <category term="ML" scheme="https://penglover.github.io/categories/ML/"/>
    
      <category term="TensorFlow" scheme="https://penglover.github.io/categories/ML/TensorFlow/"/>
    
    
      <category term="machinelearning" scheme="https://penglover.github.io/tags/machinelearning/"/>
    
      <category term="tensorflow" scheme="https://penglover.github.io/tags/tensorflow/"/>
    
  </entry>
  
  <entry>
    <title>tensorflow에서 언제 LinearRegression을 적용시킬지 알아보는 법</title>
    <link href="https://penglover.github.io/2017/01/15/tensorflow-graph/"/>
    <id>https://penglover.github.io/2017/01/15/tensorflow-graph/</id>
    <published>2017-01-15T01:22:39.000Z</published>
    <updated>2017-01-15T04:00:15.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="LinearRegression은-언제-적용시킬까요"><a href="#LinearRegression은-언제-적용시킬까요" class="headerlink" title="LinearRegression은 언제 적용시킬까요?"></a>LinearRegression은 언제 적용시킬까요?</h1><p>이것을 알기 위해서는 그래프를 그려 보는 것이 좋습니다.<br>파이썬에서는 그래프를 쉽게 그리게 해주는 라이브러리가 존재하는데요~<br>바로 matplotlib를 이용하면 아주 쉽습니다.<br>pip이 설치되어 있다면 그냥 pip install matplotlib 하시면 됩니다.<br>python3버전이신 경우에는 pip3 install matplotlib를 하시구요.<br><a href="http://matplotlib.org/users/installing.html" rel="external nofollow noopener noreferrer" target="_blank">http://matplotlib.org/users/installing.html</a> 에서 다른 설치법들도 알려줍니다~<br>설치 안되시면 댓글남겨주세요.</p>
<p>그럼 코드를 보면서 설명드리도록 하겠습니다.<br><figure class="highlight plain"><figcaption><span>matplotlib.py</span></figcaption><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div></pre></td><td class="code"><pre><div class="line">import tensorflow as tf</div><div class="line">import matplotlib.pyplot as plt</div><div class="line"></div><div class="line">X = [1., 2., 3.]</div><div class="line">Y = [1., 2., 3.]</div><div class="line">m = samples = len(X)</div><div class="line"></div><div class="line">W = tf.placeholder(tf.float32)</div><div class="line"></div><div class="line">hypothesis = tf.mul(X, W)</div><div class="line"></div><div class="line">cost = tf.reduce_sum(tf.pow(hypothesis-Y,2))/m</div><div class="line"></div><div class="line">init = tf.global_variables_initializer()</div><div class="line"></div><div class="line"></div><div class="line">W_val = []</div><div class="line">cost_val = []</div><div class="line"></div><div class="line">sess = tf.Session()</div><div class="line">sess.run(init)</div><div class="line">for i in range(-30,50):</div><div class="line">    print (i*0.1, sess.run(cost, feed_dict=&#123;W: i*0.1&#125;))</div><div class="line">    W_val.append(i*0.1)</div><div class="line">    cost_val.append(sess.run(cost, feed_dict=&#123;W: i*0.1&#125;))</div><div class="line"></div><div class="line">plt.plot(W_val, cost_val, &apos;ro&apos;)</div><div class="line">plt.ylabel(&apos;cost&apos;)</div><div class="line">plt.xlabel(&apos;W&apos;)</div><div class="line">plt.show()</div></pre></td></tr></table></figure><br>결과값은 그래프가 포함되다보니 스크린샷으로 보여드리겠습니다.<br><img src="https://penglover.github.io/images/matplotlib_sample.png" alt="matplotlib_sample"></p>
<p>자 그럼 본격적인 이야기를 해보겠습니다.<br>코드는 참 평범합니다. 그냥 hypothesis-Y에 제곱을 한 값을 평균을 내어 준 것인데요.<br>우리는 이미 X와 Y의 관계가 X * 1 = Y라는 것을 알고 있습니다.<br>X = [1, 2, 3]이고 Y = [1, 2, 3]이니 당연한 일이지요.<br>컴퓨터를 통해서 그래프를 그려보도록 하겠습니다.<br>사용법은 코드를 조금만 보시면 이해가 쉽게 가실겁니다.</p>
<p>그림처럼 저렇게 순탄한 아래쪽이 둥근모형이면 손쉽게 LinearRegression을 적용할 수 있습니다.<br>기울기 값이 줄어들거나 늘어나는 패턴이 일정하기 때문이지요.<br>수식으로 순간미분값(해당 점의 기울기값)이 0에 가까워 지도록 찾아주기만 하면 되닌까요.</p>
<p>아주 간단하죠?<br>요약하자면 연속하고 아래쪽 둥근부분이 저렇게 그림처럼 한부분만 있으면 됩니다.<br>3차원의 경우에도 마찬가지에요!</p>
]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;LinearRegression은-언제-적용시킬까요&quot;&gt;&lt;a href=&quot;#LinearRegression은-언제-적용시킬까요&quot; class=&quot;headerlink&quot; title=&quot;LinearRegression은 언제 적용시킬까요?&quot;&gt;&lt;/a&gt;Line
    
    </summary>
    
      <category term="ML" scheme="https://penglover.github.io/categories/ML/"/>
    
      <category term="TensorFlow" scheme="https://penglover.github.io/categories/ML/TensorFlow/"/>
    
    
      <category term="machinelearning" scheme="https://penglover.github.io/tags/machinelearning/"/>
    
      <category term="tensorflow" scheme="https://penglover.github.io/tags/tensorflow/"/>
    
  </entry>
  
  <entry>
    <title>텐서플로우로 linear regression 구현 및 설명</title>
    <link href="https://penglover.github.io/2017/01/14/tf-LinearRegression/"/>
    <id>https://penglover.github.io/2017/01/14/tf-LinearRegression/</id>
    <published>2017-01-14T14:50:53.000Z</published>
    <updated>2017-01-15T04:00:17.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Linear-Regression"><a href="#Linear-Regression" class="headerlink" title="Linear Regression"></a>Linear Regression</h1><p>Linear Regression에 대한 지식이 없으시다면 아래의 동영상을 보시는 것을 추천합니다.<br><a href="https://www.youtube.com/watch?v=GmtqOlPYB84" rel="external nofollow noopener noreferrer" target="_blank">https://www.youtube.com/watch?v=GmtqOlPYB84</a><br>이미 알고 계신다면 렛츠고!<br>아! 참고로 tensorflow 버전이나 python버전이 다르다면<br>tf.global_variables_initializer, print, range 부분에 수정이 필요합니다.<br>오류나면 댓글남겨주세요 ㅎㅎ 바로 알려드릴게요.</p>
<figure class="highlight plain"><figcaption><span>LinearRegression.py</span></figcaption><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div></pre></td><td class="code"><pre><div class="line">import tensorflow as tf</div><div class="line"></div><div class="line">x_data = [1, 2, 3, 4]</div><div class="line">y_data = [2, 4, 6, 8]</div><div class="line"></div><div class="line">W = tf.Variable(tf.random_uniform([1], -10000, 10000))</div><div class="line">b = tf.Variable(tf.random_uniform([1], -10000, 10000))</div><div class="line"></div><div class="line">X = tf.placeholder(tf.float32)</div><div class="line">Y = tf.placeholder(tf.float32)</div><div class="line"></div><div class="line">hypothesis = W * X + b</div><div class="line"></div><div class="line">cost = tf.reduce_mean(tf.square(hypothesis - Y))</div><div class="line"></div><div class="line">a = tf.Variable(0.1)</div><div class="line">optimizer = tf.train.GradientDescentOptimizer(a)</div><div class="line">train = optimizer.minimize(cost)</div><div class="line"></div><div class="line">init = tf.global_variables_initializer()</div><div class="line"></div><div class="line">sess = tf.Session()</div><div class="line">sess.run(init)</div><div class="line"></div><div class="line">for step in range(2001):</div><div class="line">    sess.run(train, feed_dict=&#123;X: x_data, Y: y_data&#125;)</div><div class="line">    if step % 200 == 0:</div><div class="line">        print (step, sess.run(cost, feed_dict=&#123;X: x_data, Y: y_data&#125;), sess.run(W), sess.run(b))</div><div class="line"></div><div class="line">print (sess.run(hypothesis, feed_dict=&#123;X: [5, 10]&#125;))</div><div class="line">print (sess.run(hypothesis, feed_dict=&#123;X: [2.5, 1.5]&#125;))</div></pre></td></tr></table></figure>
<p><strong>결과값</strong><br>0 1.17541e+07 [-3064.45288086] [ 7678.85205078]<br>200 53.5173 [-4.08845949] [ 17.90081406]<br>400 0.000280612 [ 1.98605835] [ 0.04099015]<br>600 1.46635e-09 [ 1.99996805] [  9.38054509e-05]<br>800 1.42109e-14 [ 1.99999988] [  4.28800519e-07]<br>1000 0.0 [ 2.] [  1.18856534e-07]<br>1200 0.0 [ 2.] [  1.18856534e-07]<br>1400 0.0 [ 2.] [  1.18856534e-07]<br>1600 0.0 [ 2.] [  1.18856534e-07]<br>1800 0.0 [ 2.] [  1.18856534e-07]<br>2000 0.0 [ 2.] [  1.18856534e-07]<br>[ 10.  20.]<br>[ 5.  3.]</p>
<p>아주 쉽게 이해가 가실 것입니다.<br>W와 b를 -10000에서 10000사이의 랜덤한 값으로 두었습니다.<br>X와 Y는 32bit의 float형 데이터로 선언해 두었지요.<br>hypothesis는 input값이 될 X에게 w와 b를 더해서 나오는 결과에 대한 기대값입니다.<br>cost는 기대값과 실제값을 뺀것을 제곱을 한 것의 평균값을 갖게 될 것입니다.<br>reduce_mean은 참고로 평균값을 내게 해주는 매소드입니다.<br>(m개의 input이 있으면 그것들의 평균값을 매겨줌)<br>a는 learning rate입니다.<br>tf.train.GradientDescentOptimizer가 gradient descent 알고리즘을 처리해줍니다.<br>그리고 minimize가 cost를 인자로 받아서 train될때마다 W와 b를 업데이트합니다.<br>화면이 너무 꽉 찰 것 같아서 step은 200개당 1번 print 했습니다.<br>결과값을 보니 training이 아주 잘 되었네요!</p>
<p>헷갈리는 tensorflow의 링크가 있다면 아래에 모든 것이 나와있습니다.<br><a href="https://www.tensorflow.org/versions/master/api_docs/python/math_ops/reduction#reduce_mean" rel="external nofollow noopener noreferrer" target="_blank">https://www.tensorflow.org/versions/master/api_docs/python/math_ops/reduction#reduce_mean</a></p>
]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;Linear-Regression&quot;&gt;&lt;a href=&quot;#Linear-Regression&quot; class=&quot;headerlink&quot; title=&quot;Linear Regression&quot;&gt;&lt;/a&gt;Linear Regression&lt;/h1&gt;&lt;p&gt;Linear Reg
    
    </summary>
    
      <category term="ML" scheme="https://penglover.github.io/categories/ML/"/>
    
      <category term="TensorFlow" scheme="https://penglover.github.io/categories/ML/TensorFlow/"/>
    
    
      <category term="machinelearning" scheme="https://penglover.github.io/tags/machinelearning/"/>
    
      <category term="tensorflow" scheme="https://penglover.github.io/tags/tensorflow/"/>
    
  </entry>
  
</feed>
